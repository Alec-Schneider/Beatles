{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_staging import create_cnn2D, fetch_images_dataframe\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, Dense\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "test_df = pd.read_csv(\"test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "target_size = (64,64)\n",
    "train_path = \"C://Users//Alec//MyPython//Beatles/train_melspec\"\n",
    "test_path = \"C://Users//Alec//MyPython//Beatles/test_melspec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 601 validated image filenames belonging to 4 classes.\n",
      "Found 150 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen, valid_gen = fetch_images_dataframe(train_df, x_col=\"song\", y_col=\"artist\", directory=train_path,\n",
    "                                                           batch_size=batch_size, target_size=target_size, \n",
    "                                                            class_mode=\"categorical\", shuffle=True, seed=1, \n",
    "                                                            validation_split=0.2, save_format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = Real(low=1e-5, high=1.0, prior='log-uniform', name='learning_rate')\n",
    "epochs = Integer(low=20, high=100, name=\"epochs\")\n",
    "input_shape = (None, 64, 64, 3)\n",
    "classes = 4\n",
    "steps_per_epoch = np.ceil(train_gen.samples/batch_size)\n",
    "validation_steps = np.ceil(valid_gen.samples/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Real(low=1e-05, high=1.0, prior='log-uniform', transform='identity')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [learning_rate, epochs]\n",
    "default_parameters = [0.00001, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = \"models/melspec/skopt_best_adam.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions)\n",
    "def fitness(learning_rate, epochs):\n",
    "    global input_shape, classes\n",
    "\n",
    "    # print the hyperparameters\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('epochs       : {0}'.format(epochs))\n",
    "\n",
    "    model = create_cnn2D(input_shape, classes, learning_rate=learning_rate, optimizer=\"Adam\")\n",
    "    \n",
    "    global train_gen, valid_gen, steps_per_epoch, validation_steps\n",
    "    class_weights = [0.25, 0.25, 0.25, 0.25]\n",
    "    history = model.fit_generator(train_gen, validation_data=valid_gen, steps_per_epoch=steps_per_epoch,\n",
    "                                validation_steps=validation_steps, epochs=epochs, class_weight=class_weights)\n",
    "    \n",
    "    accuracy = history.history['val_accuracy'][-1]\n",
    "    print(\"\\nModel accuracy: {0:.2%}\\n\".format(accuracy))\n",
    "    \n",
    "    \n",
    "    global best_accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        model.save(best_model)\n",
    "        \n",
    "        \n",
    "        best_accuracy = accuracy\n",
    "    \n",
    "    del model\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1.0e-05\n",
      "epochs       : 20\n",
      "Epoch 1/20\n",
      "26/26 [==============================] - 6s 245ms/step - loss: 1.3185 - accuracy: 0.3428 - val_loss: 1.3327 - val_accuracy: 0.3667\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 2s 73ms/step - loss: 1.3093 - accuracy: 0.3960 - val_loss: 1.2754 - val_accuracy: 0.3667\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 1.2872 - accuracy: 0.3960 - val_loss: 1.3350 - val_accuracy: 0.3667\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 1.3027 - accuracy: 0.3993 - val_loss: 1.3893 - val_accuracy: 0.4333\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 2s 85ms/step - loss: 1.2768 - accuracy: 0.3943 - val_loss: 1.2848 - val_accuracy: 0.3667\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 2s 86ms/step - loss: 1.2488 - accuracy: 0.3960 - val_loss: 1.4071 - val_accuracy: 0.3733\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 1.2431 - accuracy: 0.3993 - val_loss: 1.1068 - val_accuracy: 0.3667\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 1.2783 - accuracy: 0.3993 - val_loss: 1.1854 - val_accuracy: 0.4333\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.2138 - accuracy: 0.4060 - val_loss: 1.1210 - val_accuracy: 0.4667\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 2s 86ms/step - loss: 1.1890 - accuracy: 0.4210 - val_loss: 1.0056 - val_accuracy: 0.3933\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 1.1861 - accuracy: 0.4393 - val_loss: 1.4873 - val_accuracy: 0.4533\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.1800 - accuracy: 0.4359 - val_loss: 1.2135 - val_accuracy: 0.4067\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 1.2491 - accuracy: 0.4642 - val_loss: 1.4683 - val_accuracy: 0.4667\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.1723 - accuracy: 0.4376 - val_loss: 1.3999 - val_accuracy: 0.4533\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.2009 - accuracy: 0.4676 - val_loss: 1.1156 - val_accuracy: 0.4333\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 1.1979 - accuracy: 0.4676 - val_loss: 1.2996 - val_accuracy: 0.4467\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 1.1576 - accuracy: 0.4676 - val_loss: 1.2834 - val_accuracy: 0.4600\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 1.1393 - accuracy: 0.4809 - val_loss: 0.7011 - val_accuracy: 0.4800\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 1.2078 - accuracy: 0.4542 - val_loss: 1.3501 - val_accuracy: 0.4667\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 2s 86ms/step - loss: 1.1534 - accuracy: 0.4642 - val_loss: 0.9619 - val_accuracy: 0.4600\n",
      "\n",
      "Model accuracy: 46.00%\n",
      "\n",
      "learning rate: 9.7e-01\n",
      "epochs       : 95\n",
      "Epoch 1/95\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 1.3235 - accuracy: 0.3894 - val_loss: 0.9831 - val_accuracy: 0.3667\n",
      "Epoch 2/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 1.2905 - accuracy: 0.3960 - val_loss: 1.4468 - val_accuracy: 0.3667\n",
      "Epoch 3/95\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 1.2934 - accuracy: 0.3511 - val_loss: 1.2832 - val_accuracy: 0.3200\n",
      "Epoch 4/95\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.3232 - accuracy: 0.3744 - val_loss: 1.2239 - val_accuracy: 0.3667\n",
      "Epoch 5/95\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 1.2686 - accuracy: 0.3960 - val_loss: 1.0257 - val_accuracy: 0.3667\n",
      "Epoch 6/95\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 1.3183 - accuracy: 0.3960 - val_loss: 1.2614 - val_accuracy: 0.3667\n",
      "Epoch 7/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 1.2834 - accuracy: 0.3977 - val_loss: 1.1407 - val_accuracy: 0.4067\n",
      "Epoch 8/95\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 1.2784 - accuracy: 0.4077 - val_loss: 1.6512 - val_accuracy: 0.4467\n",
      "Epoch 9/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 1.2329 - accuracy: 0.3943 - val_loss: 1.4430 - val_accuracy: 0.3667\n",
      "Epoch 10/95\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.2436 - accuracy: 0.3977 - val_loss: 1.2824 - val_accuracy: 0.3733\n",
      "Epoch 11/95\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 1.2659 - accuracy: 0.3977 - val_loss: 0.9962 - val_accuracy: 0.4467\n",
      "Epoch 12/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 1.2171 - accuracy: 0.3860 - val_loss: 0.9781 - val_accuracy: 0.3733\n",
      "Epoch 13/95\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 1.3353 - accuracy: 0.3844 - val_loss: 1.3327 - val_accuracy: 0.3667\n",
      "Epoch 14/95\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 1.3416 - accuracy: 0.3960 - val_loss: 1.3547 - val_accuracy: 0.3667\n",
      "Epoch 15/95\n",
      "26/26 [==============================] - 2s 86ms/step - loss: 1.2977 - accuracy: 0.3960 - val_loss: 1.6652 - val_accuracy: 0.3667\n",
      "Epoch 16/95\n",
      "26/26 [==============================] - 2s 86ms/step - loss: 1.2945 - accuracy: 0.3960 - val_loss: 1.1713 - val_accuracy: 0.3667\n",
      "Epoch 17/95\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 1.3163 - accuracy: 0.3960 - val_loss: 1.3756 - val_accuracy: 0.3667\n",
      "Epoch 18/95\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 1.3049 - accuracy: 0.3960 - val_loss: 1.4484 - val_accuracy: 0.3667\n",
      "Epoch 19/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 1.2825 - accuracy: 0.3727 - val_loss: 1.4875 - val_accuracy: 0.3200\n",
      "Epoch 20/95\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 1.2814 - accuracy: 0.3827 - val_loss: 1.5937 - val_accuracy: 0.3667\n",
      "Epoch 21/95\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 1.3218 - accuracy: 0.3960 - val_loss: 1.2548 - val_accuracy: 0.3667\n",
      "Epoch 22/95\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.2690 - accuracy: 0.3960 - val_loss: 1.1214 - val_accuracy: 0.3667\n",
      "Epoch 23/95\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 1.2908 - accuracy: 0.3960 - val_loss: 1.0901 - val_accuracy: 0.3667\n",
      "Epoch 24/95\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 1.2725 - accuracy: 0.3960 - val_loss: 1.4319 - val_accuracy: 0.3667\n",
      "Epoch 25/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 1.2107 - accuracy: 0.4043 - val_loss: 1.6455 - val_accuracy: 0.3200\n",
      "Epoch 26/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 1.2696 - accuracy: 0.3644 - val_loss: 1.1512 - val_accuracy: 0.3733\n",
      "Epoch 27/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 1.2403 - accuracy: 0.4110 - val_loss: 1.3495 - val_accuracy: 0.4400\n",
      "Epoch 28/95\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 1.2049 - accuracy: 0.4343 - val_loss: 1.0353 - val_accuracy: 0.4533\n",
      "Epoch 29/95\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 1.1796 - accuracy: 0.4276 - val_loss: 1.0727 - val_accuracy: 0.4400\n",
      "Epoch 30/95\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 1.1372 - accuracy: 0.4509 - val_loss: 1.4221 - val_accuracy: 0.4667\n",
      "Epoch 31/95\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.1634 - accuracy: 0.4659 - val_loss: 1.0558 - val_accuracy: 0.4800\n",
      "Epoch 32/95\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.2156 - accuracy: 0.4459 - val_loss: 1.3563 - val_accuracy: 0.3933\n",
      "Epoch 33/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 1.1606 - accuracy: 0.4443 - val_loss: 1.1892 - val_accuracy: 0.4800\n",
      "Epoch 34/95\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 1.1290 - accuracy: 0.4725 - val_loss: 1.1175 - val_accuracy: 0.5533\n",
      "Epoch 35/95\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 1.1556 - accuracy: 0.4742 - val_loss: 0.9667 - val_accuracy: 0.4867\n",
      "Epoch 36/95\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 1.1193 - accuracy: 0.4659 - val_loss: 1.0248 - val_accuracy: 0.4600\n",
      "Epoch 37/95\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 1.2116 - accuracy: 0.4260 - val_loss: 0.9168 - val_accuracy: 0.4733\n",
      "Epoch 38/95\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 1.2178 - accuracy: 0.4276 - val_loss: 1.0820 - val_accuracy: 0.4733\n",
      "Epoch 39/95\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 1.1322 - accuracy: 0.4642 - val_loss: 1.0679 - val_accuracy: 0.5133\n",
      "Epoch 40/95\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 1.1157 - accuracy: 0.4609 - val_loss: 1.4097 - val_accuracy: 0.4267\n",
      "Epoch 41/95\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 1.1171 - accuracy: 0.5025 - val_loss: 1.2053 - val_accuracy: 0.4400\n",
      "Epoch 42/95\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.1429 - accuracy: 0.4576 - val_loss: 0.8863 - val_accuracy: 0.4733\n",
      "Epoch 43/95\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.1154 - accuracy: 0.4626 - val_loss: 0.8209 - val_accuracy: 0.5133\n",
      "Epoch 44/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 1.0865 - accuracy: 0.5175 - val_loss: 0.9240 - val_accuracy: 0.5067\n",
      "Epoch 45/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 1.0803 - accuracy: 0.4908 - val_loss: 0.8760 - val_accuracy: 0.4800\n",
      "Epoch 46/95\n",
      "26/26 [==============================] - 2s 86ms/step - loss: 1.0461 - accuracy: 0.5141 - val_loss: 0.8337 - val_accuracy: 0.5200\n",
      "Epoch 47/95\n",
      "26/26 [==============================] - 2s 85ms/step - loss: 1.0514 - accuracy: 0.5324 - val_loss: 1.0688 - val_accuracy: 0.5133\n",
      "Epoch 48/95\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 1.0638 - accuracy: 0.5241 - val_loss: 1.1223 - val_accuracy: 0.5400\n",
      "Epoch 49/95\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 1.0094 - accuracy: 0.5225 - val_loss: 0.7316 - val_accuracy: 0.4667\n",
      "Epoch 50/95\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.0524 - accuracy: 0.5175 - val_loss: 1.1096 - val_accuracy: 0.5267\n",
      "Epoch 51/95\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 1.0443 - accuracy: 0.5374 - val_loss: 1.1942 - val_accuracy: 0.4733\n",
      "Epoch 52/95\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.0343 - accuracy: 0.5025 - val_loss: 0.8856 - val_accuracy: 0.5067\n",
      "Epoch 53/95\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 1.0303 - accuracy: 0.5491 - val_loss: 0.9857 - val_accuracy: 0.5000\n",
      "Epoch 54/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.9997 - accuracy: 0.5674 - val_loss: 1.5112 - val_accuracy: 0.4667\n",
      "Epoch 55/95\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 1.0319 - accuracy: 0.5541 - val_loss: 0.9958 - val_accuracy: 0.5333\n",
      "Epoch 56/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.9594 - accuracy: 0.5591 - val_loss: 1.3940 - val_accuracy: 0.5333\n",
      "Epoch 57/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.9528 - accuracy: 0.5757 - val_loss: 1.0443 - val_accuracy: 0.4600\n",
      "Epoch 58/95\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.0770 - accuracy: 0.5208 - val_loss: 1.0649 - val_accuracy: 0.4933\n",
      "Epoch 59/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.9931 - accuracy: 0.5491 - val_loss: 1.5605 - val_accuracy: 0.5267\n",
      "Epoch 60/95\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 0.9306 - accuracy: 0.5973 - val_loss: 0.9386 - val_accuracy: 0.5333\n",
      "Epoch 61/95\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.8716 - accuracy: 0.6339 - val_loss: 1.0438 - val_accuracy: 0.4667\n",
      "Epoch 62/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.8905 - accuracy: 0.6057 - val_loss: 1.0931 - val_accuracy: 0.5333\n",
      "Epoch 63/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.8726 - accuracy: 0.6389 - val_loss: 1.8841 - val_accuracy: 0.5000\n",
      "Epoch 64/95\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.9256 - accuracy: 0.5940 - val_loss: 1.1019 - val_accuracy: 0.5067\n",
      "Epoch 65/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.9242 - accuracy: 0.6073 - val_loss: 1.0549 - val_accuracy: 0.5467\n",
      "Epoch 66/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.7902 - accuracy: 0.6805 - val_loss: 2.1447 - val_accuracy: 0.5400\n",
      "Epoch 67/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.8722 - accuracy: 0.6622 - val_loss: 2.7172 - val_accuracy: 0.4800\n",
      "Epoch 68/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.9260 - accuracy: 0.5824 - val_loss: 2.0323 - val_accuracy: 0.5200\n",
      "Epoch 69/95\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 0.8020 - accuracy: 0.6606 - val_loss: 1.5303 - val_accuracy: 0.5133\n",
      "Epoch 70/95\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.7876 - accuracy: 0.7138 - val_loss: 1.3564 - val_accuracy: 0.5200\n",
      "Epoch 71/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.7097 - accuracy: 0.7304 - val_loss: 1.1666 - val_accuracy: 0.5133\n",
      "Epoch 72/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.6607 - accuracy: 0.7188 - val_loss: 1.3297 - val_accuracy: 0.5667\n",
      "Epoch 73/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.6747 - accuracy: 0.7454 - val_loss: 2.0313 - val_accuracy: 0.5000\n",
      "Epoch 74/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.8875 - accuracy: 0.6290 - val_loss: 4.9359 - val_accuracy: 0.5800\n",
      "Epoch 75/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.8608 - accuracy: 0.6705 - val_loss: 6.1792 - val_accuracy: 0.5600\n",
      "Epoch 76/95\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.6699 - accuracy: 0.7471 - val_loss: 1.1795 - val_accuracy: 0.5600\n",
      "Epoch 77/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.6172 - accuracy: 0.7488 - val_loss: 0.7537 - val_accuracy: 0.5800\n",
      "Epoch 78/95\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.5772 - accuracy: 0.7787 - val_loss: 2.4917 - val_accuracy: 0.5400\n",
      "Epoch 79/95\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 0.6416 - accuracy: 0.7338 - val_loss: 0.8219 - val_accuracy: 0.5733\n",
      "Epoch 80/95\n",
      "26/26 [==============================] - 2s 85ms/step - loss: 0.5314 - accuracy: 0.7903 - val_loss: 0.3158 - val_accuracy: 0.5867\n",
      "Epoch 81/95\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.6859 - accuracy: 0.7255 - val_loss: 1.0469 - val_accuracy: 0.5867\n",
      "Epoch 82/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.5890 - accuracy: 0.7687 - val_loss: 0.5846 - val_accuracy: 0.5333\n",
      "Epoch 83/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.6574 - accuracy: 0.7488 - val_loss: 3.2419 - val_accuracy: 0.6000\n",
      "Epoch 84/95\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.5126 - accuracy: 0.8236 - val_loss: 6.1273 - val_accuracy: 0.5400\n",
      "Epoch 85/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.5308 - accuracy: 0.7737 - val_loss: 0.7784 - val_accuracy: 0.5667\n",
      "Epoch 86/95\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.4328 - accuracy: 0.8469 - val_loss: 0.2408 - val_accuracy: 0.5667\n",
      "Epoch 87/95\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 0.4087 - accuracy: 0.8552 - val_loss: 1.6724 - val_accuracy: 0.5800\n",
      "Epoch 88/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.3719 - accuracy: 0.8536 - val_loss: 1.1076 - val_accuracy: 0.5667\n",
      "Epoch 89/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.3309 - accuracy: 0.8852 - val_loss: 2.1924 - val_accuracy: 0.5667\n",
      "Epoch 90/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.3638 - accuracy: 0.8702 - val_loss: 1.2512 - val_accuracy: 0.5600\n",
      "Epoch 91/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.3071 - accuracy: 0.8952 - val_loss: 0.4227 - val_accuracy: 0.6133\n",
      "Epoch 92/95\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.2656 - accuracy: 0.8968 - val_loss: 0.6355 - val_accuracy: 0.5267\n",
      "Epoch 93/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.3011 - accuracy: 0.8952 - val_loss: 1.2648 - val_accuracy: 0.5000\n",
      "Epoch 94/95\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.2647 - accuracy: 0.9135 - val_loss: 1.8986 - val_accuracy: 0.5600\n",
      "Epoch 95/95\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.2362 - accuracy: 0.9251 - val_loss: 1.2347 - val_accuracy: 0.5400\n",
      "\n",
      "Model accuracy: 54.00%\n",
      "\n",
      "learning rate: 4.4e-05\n",
      "epochs       : 100\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 1.3112 - accuracy: 0.3461 - val_loss: 1.2965 - val_accuracy: 0.3667\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 1.3217 - accuracy: 0.3960 - val_loss: 1.7083 - val_accuracy: 0.4067\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 1.3197 - accuracy: 0.3927 - val_loss: 1.4348 - val_accuracy: 0.3667\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 1.2939 - accuracy: 0.4110 - val_loss: 1.1850 - val_accuracy: 0.3667\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.3400 - accuracy: 0.3827 - val_loss: 1.2650 - val_accuracy: 0.3667\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 1.2986 - accuracy: 0.3960 - val_loss: 1.3063 - val_accuracy: 0.3667\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.3058 - accuracy: 0.3960 - val_loss: 1.1919 - val_accuracy: 0.3667\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 1.2685 - accuracy: 0.3927 - val_loss: 1.4435 - val_accuracy: 0.3667\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 1.2579 - accuracy: 0.3960 - val_loss: 1.2690 - val_accuracy: 0.3667\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 1.2177 - accuracy: 0.4010 - val_loss: 0.9387 - val_accuracy: 0.3667\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 1.1903 - accuracy: 0.4176 - val_loss: 0.9086 - val_accuracy: 0.4733\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 1.2123 - accuracy: 0.4409 - val_loss: 1.0012 - val_accuracy: 0.4467\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 1.1706 - accuracy: 0.4609 - val_loss: 1.0288 - val_accuracy: 0.4533\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 2s 86ms/step - loss: 1.1649 - accuracy: 0.4459 - val_loss: 1.0166 - val_accuracy: 0.4133\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 2s 85ms/step - loss: 1.1647 - accuracy: 0.4193 - val_loss: 0.9881 - val_accuracy: 0.4600\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 2s 87ms/step - loss: 1.1511 - accuracy: 0.4725 - val_loss: 0.9013 - val_accuracy: 0.4467\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 1.1290 - accuracy: 0.4792 - val_loss: 1.3243 - val_accuracy: 0.4467\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 1.1277 - accuracy: 0.4908 - val_loss: 1.3813 - val_accuracy: 0.4733\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 1.1653 - accuracy: 0.4676 - val_loss: 1.2433 - val_accuracy: 0.4467\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.1270 - accuracy: 0.4642 - val_loss: 1.4795 - val_accuracy: 0.4867\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 1.1329 - accuracy: 0.4742 - val_loss: 2.0085 - val_accuracy: 0.4667\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.1095 - accuracy: 0.4842 - val_loss: 1.6477 - val_accuracy: 0.4467\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.1094 - accuracy: 0.4609 - val_loss: 1.5620 - val_accuracy: 0.4333\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.1201 - accuracy: 0.4908 - val_loss: 1.1783 - val_accuracy: 0.4800\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 2s 87ms/step - loss: 1.0746 - accuracy: 0.5474 - val_loss: 1.0107 - val_accuracy: 0.4800\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 1.0695 - accuracy: 0.5225 - val_loss: 1.0697 - val_accuracy: 0.4067\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 2s 85ms/step - loss: 1.0728 - accuracy: 0.5058 - val_loss: 0.9746 - val_accuracy: 0.4400\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 1.1050 - accuracy: 0.4875 - val_loss: 1.3214 - val_accuracy: 0.4933\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.0689 - accuracy: 0.5324 - val_loss: 0.7626 - val_accuracy: 0.4733\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 1.0401 - accuracy: 0.5358 - val_loss: 1.4935 - val_accuracy: 0.4667\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.0443 - accuracy: 0.5507 - val_loss: 1.5446 - val_accuracy: 0.4800\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.0605 - accuracy: 0.5541 - val_loss: 1.2437 - val_accuracy: 0.3867\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 1.0733 - accuracy: 0.5507 - val_loss: 1.3500 - val_accuracy: 0.4933\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.9635 - accuracy: 0.5757 - val_loss: 1.5245 - val_accuracy: 0.5333\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.9935 - accuracy: 0.5940 - val_loss: 0.9599 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.9220 - accuracy: 0.6123 - val_loss: 1.4048 - val_accuracy: 0.5067\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 2s 71ms/step - loss: 1.0023 - accuracy: 0.5857 - val_loss: 1.1188 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0464 - accuracy: 0.5607 - val_loss: 1.0421 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.9977 - accuracy: 0.5840 - val_loss: 0.9254 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.0671 - accuracy: 0.5308 - val_loss: 0.8674 - val_accuracy: 0.5333\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.9727 - accuracy: 0.5990 - val_loss: 0.9055 - val_accuracy: 0.5200\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.9109 - accuracy: 0.6040 - val_loss: 1.5069 - val_accuracy: 0.5533\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9147 - accuracy: 0.6223 - val_loss: 1.0672 - val_accuracy: 0.4867\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9224 - accuracy: 0.6156 - val_loss: 0.6540 - val_accuracy: 0.4867\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.8454 - accuracy: 0.6306 - val_loss: 1.0953 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.8269 - accuracy: 0.6606 - val_loss: 0.5935 - val_accuracy: 0.5467\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.8225 - accuracy: 0.6622 - val_loss: 1.0416 - val_accuracy: 0.5133\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.9367 - accuracy: 0.6589 - val_loss: 1.2563 - val_accuracy: 0.3733\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0306 - accuracy: 0.5990 - val_loss: 1.3790 - val_accuracy: 0.4133\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.0713 - accuracy: 0.5574 - val_loss: 0.8464 - val_accuracy: 0.5200\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.8836 - accuracy: 0.6290 - val_loss: 1.5113 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.7985 - accuracy: 0.6705 - val_loss: 0.9682 - val_accuracy: 0.5133\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.8495 - accuracy: 0.6556 - val_loss: 1.9648 - val_accuracy: 0.5667\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7412 - accuracy: 0.6705 - val_loss: 0.7098 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7122 - accuracy: 0.7105 - val_loss: 1.3826 - val_accuracy: 0.5333\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6961 - accuracy: 0.6988 - val_loss: 1.4526 - val_accuracy: 0.5533\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.7708 - accuracy: 0.6889 - val_loss: 0.7000 - val_accuracy: 0.5267\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.7311 - accuracy: 0.7221 - val_loss: 0.7069 - val_accuracy: 0.4733\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.7622 - accuracy: 0.6922 - val_loss: 0.8757 - val_accuracy: 0.5533\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.5811 - accuracy: 0.7637 - val_loss: 2.1799 - val_accuracy: 0.5400\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6084 - accuracy: 0.7604 - val_loss: 0.9157 - val_accuracy: 0.5667\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.5249 - accuracy: 0.8020 - val_loss: 1.2774 - val_accuracy: 0.5867\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.4776 - accuracy: 0.8303 - val_loss: 0.5808 - val_accuracy: 0.5733\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.5022 - accuracy: 0.7937 - val_loss: 0.6969 - val_accuracy: 0.5267\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.5496 - accuracy: 0.8020 - val_loss: 1.0748 - val_accuracy: 0.5600\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6798 - accuracy: 0.7388 - val_loss: 1.2028 - val_accuracy: 0.5267\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.4853 - accuracy: 0.8170 - val_loss: 0.8508 - val_accuracy: 0.5200\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.4260 - accuracy: 0.8286 - val_loss: 1.0875 - val_accuracy: 0.5733\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.3730 - accuracy: 0.8486 - val_loss: 1.2207 - val_accuracy: 0.5267\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.3616 - accuracy: 0.8619 - val_loss: 2.2917 - val_accuracy: 0.5200\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.3153 - accuracy: 0.8902 - val_loss: 0.5094 - val_accuracy: 0.4933\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.2656 - accuracy: 0.9085 - val_loss: 1.4025 - val_accuracy: 0.5933\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.3094 - accuracy: 0.8902 - val_loss: 2.2531 - val_accuracy: 0.5067\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.2513 - accuracy: 0.9068 - val_loss: 0.5280 - val_accuracy: 0.5600\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.2528 - accuracy: 0.9101 - val_loss: 0.9310 - val_accuracy: 0.5400\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.2107 - accuracy: 0.9301 - val_loss: 2.3039 - val_accuracy: 0.5400\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.2570 - accuracy: 0.9018 - val_loss: 1.1968 - val_accuracy: 0.4800\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.1951 - accuracy: 0.9368 - val_loss: 2.6193 - val_accuracy: 0.4867\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.1445 - accuracy: 0.9601 - val_loss: 3.8970 - val_accuracy: 0.5200\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.1372 - accuracy: 0.9684 - val_loss: 1.5332 - val_accuracy: 0.5333\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.1193 - accuracy: 0.9684 - val_loss: 2.9049 - val_accuracy: 0.5267\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.1152 - accuracy: 0.9717 - val_loss: 1.6005 - val_accuracy: 0.4733\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.1508 - accuracy: 0.9534 - val_loss: 1.9704 - val_accuracy: 0.5067\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.1196 - accuracy: 0.9700 - val_loss: 0.9177 - val_accuracy: 0.5067\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.0961 - accuracy: 0.9817 - val_loss: 0.6284 - val_accuracy: 0.5133\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.1231 - accuracy: 0.9584 - val_loss: 1.3719 - val_accuracy: 0.5733\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0643 - accuracy: 0.9933 - val_loss: 2.3613 - val_accuracy: 0.5267\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.0453 - accuracy: 0.9900 - val_loss: 2.7547 - val_accuracy: 0.5200\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0357 - accuracy: 0.9967 - val_loss: 1.6667 - val_accuracy: 0.5067\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.0311 - accuracy: 0.9983 - val_loss: 0.8243 - val_accuracy: 0.5267\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 4.5381 - val_accuracy: 0.5133\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.0449 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0227 - accuracy: 0.9983 - val_loss: 1.2980 - val_accuracy: 0.4933\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 3.1805 - val_accuracy: 0.5200\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.0246 - accuracy: 0.9983 - val_loss: 0.7968 - val_accuracy: 0.5133\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.0505 - accuracy: 0.9867 - val_loss: 1.3801 - val_accuracy: 0.4733\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.8292 - accuracy: 0.8037 - val_loss: 0.7788 - val_accuracy: 0.4733\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.5450 - accuracy: 0.7754 - val_loss: 0.7401 - val_accuracy: 0.5133\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.2820 - accuracy: 0.8952 - val_loss: 1.9869 - val_accuracy: 0.5533\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.1549 - accuracy: 0.9567 - val_loss: 1.1583 - val_accuracy: 0.5133\n",
      "\n",
      "Model accuracy: 51.33%\n",
      "\n",
      "learning rate: 1.5e-04\n",
      "epochs       : 52\n",
      "Epoch 1/52\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.3063 - accuracy: 0.3927 - val_loss: 1.4408 - val_accuracy: 0.3667\n",
      "Epoch 2/52\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.2900 - accuracy: 0.3960 - val_loss: 1.5065 - val_accuracy: 0.3667\n",
      "Epoch 3/52\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.2910 - accuracy: 0.3627 - val_loss: 1.2548 - val_accuracy: 0.3667\n",
      "Epoch 4/52\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.2792 - accuracy: 0.3960 - val_loss: 1.1875 - val_accuracy: 0.3667\n",
      "Epoch 5/52\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.2855 - accuracy: 0.3894 - val_loss: 1.2921 - val_accuracy: 0.3667\n",
      "Epoch 6/52\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.2520 - accuracy: 0.4143 - val_loss: 1.9569 - val_accuracy: 0.3733\n",
      "Epoch 7/52\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.2456 - accuracy: 0.3827 - val_loss: 1.3722 - val_accuracy: 0.4400\n",
      "Epoch 8/52\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.2241 - accuracy: 0.4309 - val_loss: 1.0847 - val_accuracy: 0.4000\n",
      "Epoch 9/52\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.2170 - accuracy: 0.4260 - val_loss: 1.4921 - val_accuracy: 0.3800\n",
      "Epoch 10/52\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1687 - accuracy: 0.4526 - val_loss: 1.2974 - val_accuracy: 0.4267\n",
      "Epoch 11/52\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1830 - accuracy: 0.4193 - val_loss: 0.9970 - val_accuracy: 0.4000\n",
      "Epoch 12/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1668 - accuracy: 0.4592 - val_loss: 0.6362 - val_accuracy: 0.4667\n",
      "Epoch 13/52\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1600 - accuracy: 0.4509 - val_loss: 1.2674 - val_accuracy: 0.4533\n",
      "Epoch 14/52\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1438 - accuracy: 0.4592 - val_loss: 1.7586 - val_accuracy: 0.4667\n",
      "Epoch 15/52\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.1467 - accuracy: 0.4409 - val_loss: 1.7110 - val_accuracy: 0.4667\n",
      "Epoch 16/52\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1297 - accuracy: 0.4692 - val_loss: 1.6410 - val_accuracy: 0.4467\n",
      "Epoch 17/52\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1349 - accuracy: 0.4792 - val_loss: 0.9368 - val_accuracy: 0.4467\n",
      "Epoch 18/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1089 - accuracy: 0.4809 - val_loss: 1.0654 - val_accuracy: 0.4733\n",
      "Epoch 19/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1065 - accuracy: 0.5075 - val_loss: 0.8426 - val_accuracy: 0.4333\n",
      "Epoch 20/52\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1643 - accuracy: 0.4709 - val_loss: 1.2971 - val_accuracy: 0.3867\n",
      "Epoch 21/52\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1407 - accuracy: 0.4742 - val_loss: 1.1343 - val_accuracy: 0.4933\n",
      "Epoch 22/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1326 - accuracy: 0.4775 - val_loss: 1.0685 - val_accuracy: 0.4867\n",
      "Epoch 23/52\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1015 - accuracy: 0.4825 - val_loss: 1.5167 - val_accuracy: 0.5267\n",
      "Epoch 24/52\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0983 - accuracy: 0.4892 - val_loss: 1.2758 - val_accuracy: 0.5133\n",
      "Epoch 25/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.0747 - accuracy: 0.5141 - val_loss: 1.1730 - val_accuracy: 0.5267\n",
      "Epoch 26/52\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0759 - accuracy: 0.5324 - val_loss: 1.4211 - val_accuracy: 0.5400\n",
      "Epoch 27/52\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0460 - accuracy: 0.5491 - val_loss: 1.4555 - val_accuracy: 0.5533\n",
      "Epoch 28/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1850 - accuracy: 0.4842 - val_loss: 0.9003 - val_accuracy: 0.4467\n",
      "Epoch 29/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1707 - accuracy: 0.5058 - val_loss: 0.7550 - val_accuracy: 0.4600\n",
      "Epoch 30/52\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.1854 - accuracy: 0.4992 - val_loss: 0.9023 - val_accuracy: 0.4600\n",
      "Epoch 31/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1297 - accuracy: 0.4958 - val_loss: 0.7841 - val_accuracy: 0.5267\n",
      "Epoch 32/52\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1301 - accuracy: 0.5324 - val_loss: 0.9752 - val_accuracy: 0.5467\n",
      "Epoch 33/52\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1141 - accuracy: 0.5524 - val_loss: 0.9568 - val_accuracy: 0.5533\n",
      "Epoch 34/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9968 - accuracy: 0.5807 - val_loss: 1.1995 - val_accuracy: 0.5467\n",
      "Epoch 35/52\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1070 - accuracy: 0.5574 - val_loss: 0.8358 - val_accuracy: 0.5267\n",
      "Epoch 36/52\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.9973 - accuracy: 0.5458 - val_loss: 1.0352 - val_accuracy: 0.5667\n",
      "Epoch 37/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9654 - accuracy: 0.5790 - val_loss: 1.3590 - val_accuracy: 0.5267\n",
      "Epoch 38/52\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9615 - accuracy: 0.5990 - val_loss: 1.0261 - val_accuracy: 0.5133\n",
      "Epoch 39/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.0088 - accuracy: 0.5691 - val_loss: 1.2379 - val_accuracy: 0.5733\n",
      "Epoch 40/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9260 - accuracy: 0.6223 - val_loss: 1.0307 - val_accuracy: 0.4867\n",
      "Epoch 41/52\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.9630 - accuracy: 0.5857 - val_loss: 0.7596 - val_accuracy: 0.5067\n",
      "Epoch 42/52\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9703 - accuracy: 0.6023 - val_loss: 1.2036 - val_accuracy: 0.5467\n",
      "Epoch 43/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9467 - accuracy: 0.6156 - val_loss: 1.1143 - val_accuracy: 0.4733\n",
      "Epoch 44/52\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9336 - accuracy: 0.6123 - val_loss: 0.8445 - val_accuracy: 0.5400\n",
      "Epoch 45/52\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.8611 - accuracy: 0.6273 - val_loss: 1.3158 - val_accuracy: 0.5667\n",
      "Epoch 46/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.8789 - accuracy: 0.6206 - val_loss: 0.7805 - val_accuracy: 0.5800\n",
      "Epoch 47/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.8870 - accuracy: 0.6190 - val_loss: 0.9452 - val_accuracy: 0.5867\n",
      "Epoch 48/52\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.8635 - accuracy: 0.6423 - val_loss: 0.6959 - val_accuracy: 0.5733\n",
      "Epoch 49/52\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.8900 - accuracy: 0.6456 - val_loss: 0.7589 - val_accuracy: 0.5667\n",
      "Epoch 50/52\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.8939 - accuracy: 0.6423 - val_loss: 1.3904 - val_accuracy: 0.5333\n",
      "Epoch 51/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.7914 - accuracy: 0.6606 - val_loss: 1.8853 - val_accuracy: 0.5667\n",
      "Epoch 52/52\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.7951 - accuracy: 0.6705 - val_loss: 1.5570 - val_accuracy: 0.5067\n",
      "\n",
      "Model accuracy: 50.67%\n",
      "\n",
      "learning rate: 8.7e-04\n",
      "epochs       : 74\n",
      "Epoch 1/74\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.3482 - accuracy: 0.3577 - val_loss: 1.2659 - val_accuracy: 0.3667\n",
      "Epoch 2/74\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.3390 - accuracy: 0.3960 - val_loss: 1.4159 - val_accuracy: 0.3667\n",
      "Epoch 3/74\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.3087 - accuracy: 0.3478 - val_loss: 1.2778 - val_accuracy: 0.3667\n",
      "Epoch 4/74\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.2811 - accuracy: 0.3960 - val_loss: 1.0737 - val_accuracy: 0.3667\n",
      "Epoch 5/74\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2804 - accuracy: 0.3960 - val_loss: 1.2439 - val_accuracy: 0.3667\n",
      "Epoch 6/74\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.2831 - accuracy: 0.4060 - val_loss: 1.3769 - val_accuracy: 0.4267\n",
      "Epoch 7/74\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 1.2355 - accuracy: 0.4193 - val_loss: 1.2465 - val_accuracy: 0.4000\n",
      "Epoch 8/74\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.2516 - accuracy: 0.3960 - val_loss: 1.3133 - val_accuracy: 0.4333\n",
      "Epoch 9/74\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.2302 - accuracy: 0.4210 - val_loss: 1.1522 - val_accuracy: 0.4067\n",
      "Epoch 10/74\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.2045 - accuracy: 0.4359 - val_loss: 1.4352 - val_accuracy: 0.4467\n",
      "Epoch 11/74\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1719 - accuracy: 0.4559 - val_loss: 1.4946 - val_accuracy: 0.4267\n",
      "Epoch 12/74\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1731 - accuracy: 0.4359 - val_loss: 1.5974 - val_accuracy: 0.4267\n",
      "Epoch 13/74\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1641 - accuracy: 0.4493 - val_loss: 1.3246 - val_accuracy: 0.4667\n",
      "Epoch 14/74\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.1612 - accuracy: 0.4493 - val_loss: 1.0865 - val_accuracy: 0.4400\n",
      "Epoch 15/74\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1990 - accuracy: 0.4443 - val_loss: 0.7426 - val_accuracy: 0.4067\n",
      "Epoch 16/74\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1837 - accuracy: 0.4343 - val_loss: 1.9932 - val_accuracy: 0.4400\n",
      "Epoch 17/74\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1883 - accuracy: 0.4792 - val_loss: 1.1604 - val_accuracy: 0.4667\n",
      "Epoch 18/74\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1297 - accuracy: 0.4626 - val_loss: 1.0891 - val_accuracy: 0.4400\n",
      "Epoch 19/74\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1457 - accuracy: 0.5008 - val_loss: 1.3145 - val_accuracy: 0.4533\n",
      "Epoch 20/74\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.1708 - accuracy: 0.4592 - val_loss: 1.1012 - val_accuracy: 0.4600\n",
      "Epoch 21/74\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1919 - accuracy: 0.4343 - val_loss: 1.2936 - val_accuracy: 0.4333\n",
      "Epoch 22/74\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1553 - accuracy: 0.4842 - val_loss: 1.6409 - val_accuracy: 0.4467\n",
      "Epoch 23/74\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1208 - accuracy: 0.4809 - val_loss: 1.0579 - val_accuracy: 0.4533\n",
      "Epoch 24/74\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1194 - accuracy: 0.4559 - val_loss: 0.7677 - val_accuracy: 0.4533\n",
      "Epoch 25/74\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1555 - accuracy: 0.4542 - val_loss: 1.0436 - val_accuracy: 0.4333\n",
      "Epoch 26/74\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1137 - accuracy: 0.4908 - val_loss: 1.3848 - val_accuracy: 0.4800\n",
      "Epoch 27/74\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0894 - accuracy: 0.4892 - val_loss: 0.9853 - val_accuracy: 0.4533\n",
      "Epoch 28/74\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0998 - accuracy: 0.5042 - val_loss: 1.2088 - val_accuracy: 0.5200\n",
      "Epoch 29/74\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.0889 - accuracy: 0.5092 - val_loss: 0.8246 - val_accuracy: 0.5000\n",
      "Epoch 30/74\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1247 - accuracy: 0.4742 - val_loss: 1.2415 - val_accuracy: 0.4667\n",
      "Epoch 31/74\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0841 - accuracy: 0.5075 - val_loss: 0.8989 - val_accuracy: 0.5000\n",
      "Epoch 32/74\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.0516 - accuracy: 0.5175 - val_loss: 1.0253 - val_accuracy: 0.4467\n",
      "Epoch 33/74\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.0285 - accuracy: 0.5308 - val_loss: 1.1417 - val_accuracy: 0.4600\n",
      "Epoch 34/74\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.0238 - accuracy: 0.5241 - val_loss: 1.3753 - val_accuracy: 0.4933\n",
      "Epoch 35/74\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.0577 - accuracy: 0.5241 - val_loss: 1.5130 - val_accuracy: 0.5133\n",
      "Epoch 36/74\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 1.0849 - accuracy: 0.5358 - val_loss: 1.3173 - val_accuracy: 0.5000\n",
      "Epoch 37/74\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 1.0847 - accuracy: 0.5042 - val_loss: 1.5436 - val_accuracy: 0.4600\n",
      "Epoch 38/74\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0773 - accuracy: 0.5441 - val_loss: 1.6133 - val_accuracy: 0.4733\n",
      "Epoch 39/74\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1099 - accuracy: 0.5258 - val_loss: 1.3959 - val_accuracy: 0.4800\n",
      "Epoch 40/74\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.0336 - accuracy: 0.5324 - val_loss: 1.0722 - val_accuracy: 0.5400\n",
      "Epoch 41/74\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.0553 - accuracy: 0.5424 - val_loss: 0.6393 - val_accuracy: 0.4800\n",
      "Epoch 42/74\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0666 - accuracy: 0.5341 - val_loss: 1.5482 - val_accuracy: 0.5000\n",
      "Epoch 43/74\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.9384 - accuracy: 0.5724 - val_loss: 0.9624 - val_accuracy: 0.5133\n",
      "Epoch 44/74\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9933 - accuracy: 0.5790 - val_loss: 1.1382 - val_accuracy: 0.5133\n",
      "Epoch 45/74\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9880 - accuracy: 0.5624 - val_loss: 0.7615 - val_accuracy: 0.4933\n",
      "Epoch 46/74\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.9179 - accuracy: 0.5957 - val_loss: 1.3452 - val_accuracy: 0.5333\n",
      "Epoch 47/74\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9978 - accuracy: 0.5890 - val_loss: 1.1601 - val_accuracy: 0.5333\n",
      "Epoch 48/74\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9949 - accuracy: 0.5824 - val_loss: 1.7159 - val_accuracy: 0.5200\n",
      "Epoch 49/74\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0338 - accuracy: 0.5624 - val_loss: 0.9000 - val_accuracy: 0.5067\n",
      "Epoch 50/74\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.8977 - accuracy: 0.6240 - val_loss: 1.4470 - val_accuracy: 0.4800\n",
      "Epoch 51/74\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.8939 - accuracy: 0.6206 - val_loss: 1.6603 - val_accuracy: 0.5067\n",
      "Epoch 52/74\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.0174 - accuracy: 0.5391 - val_loss: 1.1959 - val_accuracy: 0.4867\n",
      "Epoch 53/74\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9046 - accuracy: 0.6023 - val_loss: 1.1450 - val_accuracy: 0.5200\n",
      "Epoch 54/74\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.8466 - accuracy: 0.6406 - val_loss: 0.5454 - val_accuracy: 0.5000\n",
      "Epoch 55/74\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9611 - accuracy: 0.6123 - val_loss: 1.4477 - val_accuracy: 0.5133\n",
      "Epoch 56/74\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.8649 - accuracy: 0.6190 - val_loss: 1.4779 - val_accuracy: 0.5467\n",
      "Epoch 57/74\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7741 - accuracy: 0.6805 - val_loss: 2.0707 - val_accuracy: 0.5267\n",
      "Epoch 58/74\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.7350 - accuracy: 0.7038 - val_loss: 1.9687 - val_accuracy: 0.5333\n",
      "Epoch 59/74\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.7240 - accuracy: 0.6922 - val_loss: 1.1260 - val_accuracy: 0.5600\n",
      "Epoch 60/74\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 0.7352 - accuracy: 0.7072 - val_loss: 0.8262 - val_accuracy: 0.5267\n",
      "Epoch 61/74\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.7401 - accuracy: 0.6672 - val_loss: 0.7100 - val_accuracy: 0.5667\n",
      "Epoch 62/74\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.7485 - accuracy: 0.6872 - val_loss: 1.6821 - val_accuracy: 0.5600\n",
      "Epoch 63/74\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.7729 - accuracy: 0.6922 - val_loss: 0.9324 - val_accuracy: 0.5267\n",
      "Epoch 64/74\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6449 - accuracy: 0.7471 - val_loss: 0.7762 - val_accuracy: 0.5467\n",
      "Epoch 65/74\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6660 - accuracy: 0.7504 - val_loss: 1.3208 - val_accuracy: 0.5667\n",
      "Epoch 66/74\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6364 - accuracy: 0.7321 - val_loss: 1.9065 - val_accuracy: 0.5333\n",
      "Epoch 67/74\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6916 - accuracy: 0.7504 - val_loss: 1.6531 - val_accuracy: 0.4467\n",
      "Epoch 68/74\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.8442 - accuracy: 0.6389 - val_loss: 0.9611 - val_accuracy: 0.5333\n",
      "Epoch 69/74\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6857 - accuracy: 0.7271 - val_loss: 0.7545 - val_accuracy: 0.5333\n",
      "Epoch 70/74\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6049 - accuracy: 0.7687 - val_loss: 1.4166 - val_accuracy: 0.5600\n",
      "Epoch 71/74\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.5438 - accuracy: 0.7854 - val_loss: 2.4280 - val_accuracy: 0.5333\n",
      "Epoch 72/74\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.5071 - accuracy: 0.8070 - val_loss: 1.4980 - val_accuracy: 0.5400\n",
      "Epoch 73/74\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6678 - accuracy: 0.7554 - val_loss: 0.4735 - val_accuracy: 0.5200\n",
      "Epoch 74/74\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.5732 - accuracy: 0.7720 - val_loss: 1.3327 - val_accuracy: 0.5333\n",
      "\n",
      "Model accuracy: 53.33%\n",
      "\n",
      "learning rate: 4.8e-01\n",
      "epochs       : 88\n",
      "Epoch 1/88\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.3110 - accuracy: 0.3744 - val_loss: 1.6324 - val_accuracy: 0.3667\n",
      "Epoch 2/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.3226 - accuracy: 0.3078 - val_loss: 1.3324 - val_accuracy: 0.3667\n",
      "Epoch 3/88\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.3111 - accuracy: 0.3960 - val_loss: 1.1808 - val_accuracy: 0.3667\n",
      "Epoch 4/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.3042 - accuracy: 0.3960 - val_loss: 1.3108 - val_accuracy: 0.3667\n",
      "Epoch 5/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2879 - accuracy: 0.3960 - val_loss: 1.1973 - val_accuracy: 0.3667\n",
      "Epoch 6/88\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.3082 - accuracy: 0.3943 - val_loss: 1.3430 - val_accuracy: 0.3667\n",
      "Epoch 7/88\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.2726 - accuracy: 0.3977 - val_loss: 1.4179 - val_accuracy: 0.3667\n",
      "Epoch 8/88\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.2300 - accuracy: 0.3977 - val_loss: 1.7887 - val_accuracy: 0.3667\n",
      "Epoch 9/88\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.2680 - accuracy: 0.4077 - val_loss: 1.4511 - val_accuracy: 0.4333\n",
      "Epoch 10/88\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.2488 - accuracy: 0.4126 - val_loss: 1.2473 - val_accuracy: 0.4400\n",
      "Epoch 11/88\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.2484 - accuracy: 0.4343 - val_loss: 1.0865 - val_accuracy: 0.4333\n",
      "Epoch 12/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2387 - accuracy: 0.4110 - val_loss: 1.3756 - val_accuracy: 0.3667\n",
      "Epoch 13/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1704 - accuracy: 0.4443 - val_loss: 1.1887 - val_accuracy: 0.3667\n",
      "Epoch 14/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1662 - accuracy: 0.4459 - val_loss: 1.0137 - val_accuracy: 0.4533\n",
      "Epoch 15/88\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.1554 - accuracy: 0.4526 - val_loss: 1.3159 - val_accuracy: 0.4333\n",
      "Epoch 16/88\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.1410 - accuracy: 0.4809 - val_loss: 1.5320 - val_accuracy: 0.4467\n",
      "Epoch 17/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1495 - accuracy: 0.4725 - val_loss: 1.5606 - val_accuracy: 0.4533\n",
      "Epoch 18/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2249 - accuracy: 0.4359 - val_loss: 1.3409 - val_accuracy: 0.3733\n",
      "Epoch 19/88\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1490 - accuracy: 0.4243 - val_loss: 0.9806 - val_accuracy: 0.4867\n",
      "Epoch 20/88\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1741 - accuracy: 0.4476 - val_loss: 1.6160 - val_accuracy: 0.4467\n",
      "Epoch 21/88\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1303 - accuracy: 0.4725 - val_loss: 0.9382 - val_accuracy: 0.4400\n",
      "Epoch 22/88\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1197 - accuracy: 0.5042 - val_loss: 1.0788 - val_accuracy: 0.5000\n",
      "Epoch 23/88\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.2221 - accuracy: 0.4725 - val_loss: 1.2213 - val_accuracy: 0.4067\n",
      "Epoch 24/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2479 - accuracy: 0.3927 - val_loss: 1.2257 - val_accuracy: 0.4067\n",
      "Epoch 25/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1604 - accuracy: 0.4459 - val_loss: 1.3123 - val_accuracy: 0.4133\n",
      "Epoch 26/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1350 - accuracy: 0.4759 - val_loss: 1.3169 - val_accuracy: 0.4867\n",
      "Epoch 27/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0859 - accuracy: 0.5241 - val_loss: 1.7498 - val_accuracy: 0.5000\n",
      "Epoch 28/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1569 - accuracy: 0.4908 - val_loss: 1.0385 - val_accuracy: 0.4933\n",
      "Epoch 29/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0979 - accuracy: 0.4775 - val_loss: 1.2721 - val_accuracy: 0.4800\n",
      "Epoch 30/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1310 - accuracy: 0.4493 - val_loss: 1.0863 - val_accuracy: 0.4867\n",
      "Epoch 31/88\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.0794 - accuracy: 0.5225 - val_loss: 0.9347 - val_accuracy: 0.4800\n",
      "Epoch 32/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1194 - accuracy: 0.4792 - val_loss: 1.0437 - val_accuracy: 0.4800\n",
      "Epoch 33/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1201 - accuracy: 0.5042 - val_loss: 1.4576 - val_accuracy: 0.4733\n",
      "Epoch 34/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0350 - accuracy: 0.5391 - val_loss: 1.0409 - val_accuracy: 0.5067\n",
      "Epoch 35/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0628 - accuracy: 0.5524 - val_loss: 1.4939 - val_accuracy: 0.4933\n",
      "Epoch 36/88\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.0153 - accuracy: 0.5624 - val_loss: 0.8457 - val_accuracy: 0.5067\n",
      "Epoch 37/88\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.0723 - accuracy: 0.5341 - val_loss: 1.2725 - val_accuracy: 0.4933\n",
      "Epoch 38/88\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.0104 - accuracy: 0.5607 - val_loss: 1.0760 - val_accuracy: 0.5333\n",
      "Epoch 39/88\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.9784 - accuracy: 0.5541 - val_loss: 1.1053 - val_accuracy: 0.5067\n",
      "Epoch 40/88\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.9644 - accuracy: 0.5657 - val_loss: 1.2345 - val_accuracy: 0.5333\n",
      "Epoch 41/88\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9748 - accuracy: 0.5541 - val_loss: 1.2869 - val_accuracy: 0.5267\n",
      "Epoch 42/88\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9292 - accuracy: 0.5874 - val_loss: 1.3721 - val_accuracy: 0.5267\n",
      "Epoch 43/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0014 - accuracy: 0.5757 - val_loss: 0.8773 - val_accuracy: 0.5333\n",
      "Epoch 44/88\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9153 - accuracy: 0.6190 - val_loss: 0.8444 - val_accuracy: 0.4667\n",
      "Epoch 45/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.9210 - accuracy: 0.5940 - val_loss: 1.0413 - val_accuracy: 0.5667\n",
      "Epoch 46/88\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.9365 - accuracy: 0.5957 - val_loss: 0.8719 - val_accuracy: 0.5133\n",
      "Epoch 47/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9238 - accuracy: 0.6007 - val_loss: 0.5257 - val_accuracy: 0.5333\n",
      "Epoch 48/88\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9169 - accuracy: 0.5990 - val_loss: 0.7065 - val_accuracy: 0.5467\n",
      "Epoch 49/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.8702 - accuracy: 0.6323 - val_loss: 1.3656 - val_accuracy: 0.5400\n",
      "Epoch 50/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9330 - accuracy: 0.6040 - val_loss: 1.3206 - val_accuracy: 0.4533\n",
      "Epoch 51/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.9248 - accuracy: 0.6140 - val_loss: 1.5815 - val_accuracy: 0.5267\n",
      "Epoch 52/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.8687 - accuracy: 0.6173 - val_loss: 1.7600 - val_accuracy: 0.5267\n",
      "Epoch 53/88\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.8085 - accuracy: 0.6739 - val_loss: 1.3584 - val_accuracy: 0.5200\n",
      "Epoch 54/88\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.8173 - accuracy: 0.6705 - val_loss: 0.6715 - val_accuracy: 0.5400\n",
      "Epoch 55/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.8531 - accuracy: 0.6439 - val_loss: 1.0447 - val_accuracy: 0.5267\n",
      "Epoch 56/88\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.7983 - accuracy: 0.6556 - val_loss: 1.7222 - val_accuracy: 0.5000\n",
      "Epoch 57/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7436 - accuracy: 0.6855 - val_loss: 0.9126 - val_accuracy: 0.4867\n",
      "Epoch 58/88\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.7369 - accuracy: 0.6739 - val_loss: 0.8385 - val_accuracy: 0.5333\n",
      "Epoch 59/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6623 - accuracy: 0.7304 - val_loss: 1.5374 - val_accuracy: 0.5333\n",
      "Epoch 60/88\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6933 - accuracy: 0.7072 - val_loss: 0.8860 - val_accuracy: 0.4600\n",
      "Epoch 61/88\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.6632 - accuracy: 0.7288 - val_loss: 0.6685 - val_accuracy: 0.5267\n",
      "Epoch 62/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6668 - accuracy: 0.7188 - val_loss: 1.0973 - val_accuracy: 0.5667\n",
      "Epoch 63/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7234 - accuracy: 0.7238 - val_loss: 1.4202 - val_accuracy: 0.4933\n",
      "Epoch 64/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.8589 - accuracy: 0.6656 - val_loss: 0.9948 - val_accuracy: 0.5400\n",
      "Epoch 65/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6332 - accuracy: 0.7388 - val_loss: 1.1189 - val_accuracy: 0.6133\n",
      "Epoch 66/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6570 - accuracy: 0.7321 - val_loss: 0.7045 - val_accuracy: 0.4800\n",
      "Epoch 67/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6202 - accuracy: 0.7371 - val_loss: 0.8511 - val_accuracy: 0.4600\n",
      "Epoch 68/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.7403 - accuracy: 0.6988 - val_loss: 1.2806 - val_accuracy: 0.5533\n",
      "Epoch 69/88\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.5250 - accuracy: 0.8120 - val_loss: 0.7879 - val_accuracy: 0.5600\n",
      "Epoch 70/88\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 0.5465 - accuracy: 0.7820 - val_loss: 1.2748 - val_accuracy: 0.5667\n",
      "Epoch 71/88\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.5036 - accuracy: 0.7887 - val_loss: 0.7377 - val_accuracy: 0.4933\n",
      "Epoch 72/88\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.5485 - accuracy: 0.7737 - val_loss: 0.8668 - val_accuracy: 0.5867\n",
      "Epoch 73/88\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.4850 - accuracy: 0.8087 - val_loss: 0.6482 - val_accuracy: 0.5733\n",
      "Epoch 74/88\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.4263 - accuracy: 0.8319 - val_loss: 0.3365 - val_accuracy: 0.5533\n",
      "Epoch 75/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.3760 - accuracy: 0.8619 - val_loss: 1.4310 - val_accuracy: 0.5667\n",
      "Epoch 76/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.4175 - accuracy: 0.8203 - val_loss: 0.8678 - val_accuracy: 0.5267\n",
      "Epoch 77/88\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.3939 - accuracy: 0.8552 - val_loss: 1.8918 - val_accuracy: 0.5333\n",
      "Epoch 78/88\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6090 - accuracy: 0.7554 - val_loss: 1.8862 - val_accuracy: 0.5467\n",
      "Epoch 79/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.5402 - accuracy: 0.8153 - val_loss: 1.4250 - val_accuracy: 0.4867\n",
      "Epoch 80/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.4935 - accuracy: 0.8003 - val_loss: 0.6274 - val_accuracy: 0.5267\n",
      "Epoch 81/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.3374 - accuracy: 0.8752 - val_loss: 0.5622 - val_accuracy: 0.5133\n",
      "Epoch 82/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.3321 - accuracy: 0.8985 - val_loss: 2.4180 - val_accuracy: 0.4933\n",
      "Epoch 83/88\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.3925 - accuracy: 0.8536 - val_loss: 0.2969 - val_accuracy: 0.5667\n",
      "Epoch 84/88\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.2693 - accuracy: 0.9068 - val_loss: 0.5154 - val_accuracy: 0.5133\n",
      "Epoch 85/88\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.7080 - accuracy: 0.7720 - val_loss: 1.7942 - val_accuracy: 0.4867\n",
      "Epoch 86/88\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.5199 - accuracy: 0.8220 - val_loss: 0.6457 - val_accuracy: 0.5000\n",
      "Epoch 87/88\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.4831 - accuracy: 0.8203 - val_loss: 2.8000 - val_accuracy: 0.5000\n",
      "Epoch 88/88\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.3583 - accuracy: 0.8769 - val_loss: 1.0736 - val_accuracy: 0.5400\n",
      "\n",
      "Model accuracy: 54.00%\n",
      "\n",
      "learning rate: 3.7e-04\n",
      "epochs       : 62\n",
      "Epoch 1/62\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.3191 - accuracy: 0.3161 - val_loss: 1.3047 - val_accuracy: 0.3200\n",
      "Epoch 2/62\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.2912 - accuracy: 0.3860 - val_loss: 1.4812 - val_accuracy: 0.3667\n",
      "Epoch 3/62\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 1.2798 - accuracy: 0.3960 - val_loss: 1.0268 - val_accuracy: 0.3667\n",
      "Epoch 4/62\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.3207 - accuracy: 0.3960 - val_loss: 1.4248 - val_accuracy: 0.3667\n",
      "Epoch 5/62\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 1.2493 - accuracy: 0.3960 - val_loss: 1.0863 - val_accuracy: 0.3667\n",
      "Epoch 6/62\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.2533 - accuracy: 0.4043 - val_loss: 1.5280 - val_accuracy: 0.3667\n",
      "Epoch 7/62\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.2413 - accuracy: 0.3977 - val_loss: 1.2873 - val_accuracy: 0.3667\n",
      "Epoch 8/62\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.3553 - accuracy: 0.3943 - val_loss: 1.2754 - val_accuracy: 0.3667\n",
      "Epoch 9/62\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.2659 - accuracy: 0.3960 - val_loss: 1.3583 - val_accuracy: 0.3667\n",
      "Epoch 10/62\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.2453 - accuracy: 0.3877 - val_loss: 0.9834 - val_accuracy: 0.4067\n",
      "Epoch 11/62\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.2136 - accuracy: 0.4043 - val_loss: 1.1594 - val_accuracy: 0.4467\n",
      "Epoch 12/62\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.1692 - accuracy: 0.4376 - val_loss: 1.1952 - val_accuracy: 0.4267\n",
      "Epoch 13/62\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.2263 - accuracy: 0.4210 - val_loss: 1.3597 - val_accuracy: 0.3800\n",
      "Epoch 14/62\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.2257 - accuracy: 0.4359 - val_loss: 1.1781 - val_accuracy: 0.4333\n",
      "Epoch 15/62\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.1640 - accuracy: 0.4559 - val_loss: 1.3908 - val_accuracy: 0.4667\n",
      "Epoch 16/62\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.1680 - accuracy: 0.4376 - val_loss: 0.8518 - val_accuracy: 0.4400\n",
      "Epoch 17/62\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.1840 - accuracy: 0.4542 - val_loss: 1.3481 - val_accuracy: 0.4467\n",
      "Epoch 18/62\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1560 - accuracy: 0.4692 - val_loss: 0.8324 - val_accuracy: 0.4733\n",
      "Epoch 19/62\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1450 - accuracy: 0.4509 - val_loss: 1.1070 - val_accuracy: 0.4600\n",
      "Epoch 20/62\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.1571 - accuracy: 0.4592 - val_loss: 1.0781 - val_accuracy: 0.4867\n",
      "Epoch 21/62\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1042 - accuracy: 0.4775 - val_loss: 1.2000 - val_accuracy: 0.4067\n",
      "Epoch 22/62\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1362 - accuracy: 0.4759 - val_loss: 1.5840 - val_accuracy: 0.4733\n",
      "Epoch 23/62\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1161 - accuracy: 0.4659 - val_loss: 1.0900 - val_accuracy: 0.5000\n",
      "Epoch 24/62\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1641 - accuracy: 0.4842 - val_loss: 0.9375 - val_accuracy: 0.4667\n",
      "Epoch 25/62\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1704 - accuracy: 0.4592 - val_loss: 0.8795 - val_accuracy: 0.4600\n",
      "Epoch 26/62\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.0945 - accuracy: 0.4859 - val_loss: 1.2991 - val_accuracy: 0.4600\n",
      "Epoch 27/62\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.1244 - accuracy: 0.5008 - val_loss: 1.1328 - val_accuracy: 0.4667\n",
      "Epoch 28/62\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.2044 - accuracy: 0.4942 - val_loss: 1.3557 - val_accuracy: 0.3600\n",
      "Epoch 29/62\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.1770 - accuracy: 0.4493 - val_loss: 1.0611 - val_accuracy: 0.4800\n",
      "Epoch 30/62\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1665 - accuracy: 0.4792 - val_loss: 1.4589 - val_accuracy: 0.4733\n",
      "Epoch 31/62\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0625 - accuracy: 0.5208 - val_loss: 2.3017 - val_accuracy: 0.4600\n",
      "Epoch 32/62\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.1649 - accuracy: 0.5042 - val_loss: 1.0318 - val_accuracy: 0.4600\n",
      "Epoch 33/62\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.0866 - accuracy: 0.5042 - val_loss: 1.0155 - val_accuracy: 0.4867\n",
      "Epoch 34/62\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1350 - accuracy: 0.4742 - val_loss: 1.2691 - val_accuracy: 0.5067\n",
      "Epoch 35/62\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.0747 - accuracy: 0.5241 - val_loss: 0.7332 - val_accuracy: 0.4867\n",
      "Epoch 36/62\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0276 - accuracy: 0.5225 - val_loss: 1.2725 - val_accuracy: 0.4667\n",
      "Epoch 37/62\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0219 - accuracy: 0.5275 - val_loss: 1.0158 - val_accuracy: 0.5000\n",
      "Epoch 38/62\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1072 - accuracy: 0.5108 - val_loss: 0.8778 - val_accuracy: 0.5400\n",
      "Epoch 39/62\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0876 - accuracy: 0.5175 - val_loss: 1.0896 - val_accuracy: 0.4800\n",
      "Epoch 40/62\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0111 - accuracy: 0.5607 - val_loss: 1.3919 - val_accuracy: 0.5067\n",
      "Epoch 41/62\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0878 - accuracy: 0.5308 - val_loss: 1.1203 - val_accuracy: 0.5067\n",
      "Epoch 42/62\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.0496 - accuracy: 0.5424 - val_loss: 1.2172 - val_accuracy: 0.5200\n",
      "Epoch 43/62\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0428 - accuracy: 0.5624 - val_loss: 1.0439 - val_accuracy: 0.4067\n",
      "Epoch 44/62\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.1055 - accuracy: 0.4908 - val_loss: 1.0730 - val_accuracy: 0.4800\n",
      "Epoch 45/62\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9884 - accuracy: 0.5641 - val_loss: 0.7713 - val_accuracy: 0.5200\n",
      "Epoch 46/62\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.0270 - accuracy: 0.5474 - val_loss: 1.3396 - val_accuracy: 0.4600\n",
      "Epoch 47/62\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.9652 - accuracy: 0.5724 - val_loss: 1.3499 - val_accuracy: 0.5133\n",
      "Epoch 48/62\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9083 - accuracy: 0.5923 - val_loss: 0.5768 - val_accuracy: 0.5467\n",
      "Epoch 49/62\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0865 - accuracy: 0.5973 - val_loss: 1.2188 - val_accuracy: 0.3667\n",
      "Epoch 50/62\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.1250 - accuracy: 0.4908 - val_loss: 1.3915 - val_accuracy: 0.4800\n",
      "Epoch 51/62\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9980 - accuracy: 0.5624 - val_loss: 1.2845 - val_accuracy: 0.5267\n",
      "Epoch 52/62\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.0522 - accuracy: 0.5474 - val_loss: 1.1851 - val_accuracy: 0.4800\n",
      "Epoch 53/62\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.9437 - accuracy: 0.5990 - val_loss: 0.8147 - val_accuracy: 0.5267\n",
      "Epoch 54/62\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.8961 - accuracy: 0.6223 - val_loss: 1.0683 - val_accuracy: 0.5533\n",
      "Epoch 55/62\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.9493 - accuracy: 0.6040 - val_loss: 2.1408 - val_accuracy: 0.4933\n",
      "Epoch 56/62\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.8732 - accuracy: 0.6489 - val_loss: 1.0462 - val_accuracy: 0.4800\n",
      "Epoch 57/62\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.9680 - accuracy: 0.6223 - val_loss: 1.1541 - val_accuracy: 0.5200\n",
      "Epoch 58/62\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.9109 - accuracy: 0.6240 - val_loss: 1.4265 - val_accuracy: 0.5333\n",
      "Epoch 59/62\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.8653 - accuracy: 0.6306 - val_loss: 1.2588 - val_accuracy: 0.5400\n",
      "Epoch 60/62\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0600 - accuracy: 0.5790 - val_loss: 0.7664 - val_accuracy: 0.5200\n",
      "Epoch 61/62\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.8757 - accuracy: 0.6339 - val_loss: 0.8891 - val_accuracy: 0.4933\n",
      "Epoch 62/62\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.8005 - accuracy: 0.6606 - val_loss: 0.8885 - val_accuracy: 0.5400\n",
      "\n",
      "Model accuracy: 54.00%\n",
      "\n",
      "learning rate: 1.6e-03\n",
      "epochs       : 38\n",
      "Epoch 1/38\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.3231 - accuracy: 0.3777 - val_loss: 1.4706 - val_accuracy: 0.3667\n",
      "Epoch 2/38\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.3017 - accuracy: 0.3860 - val_loss: 1.6764 - val_accuracy: 0.3667\n",
      "Epoch 3/38\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.2849 - accuracy: 0.3960 - val_loss: 1.1282 - val_accuracy: 0.3667\n",
      "Epoch 4/38\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.3214 - accuracy: 0.3960 - val_loss: 1.3490 - val_accuracy: 0.3667\n",
      "Epoch 5/38\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.2773 - accuracy: 0.3960 - val_loss: 1.2781 - val_accuracy: 0.3667\n",
      "Epoch 6/38\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.2618 - accuracy: 0.3960 - val_loss: 1.1793 - val_accuracy: 0.3667\n",
      "Epoch 7/38\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.2596 - accuracy: 0.3960 - val_loss: 1.0233 - val_accuracy: 0.3867\n",
      "Epoch 8/38\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.2349 - accuracy: 0.3894 - val_loss: 1.3103 - val_accuracy: 0.3667\n",
      "Epoch 9/38\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1955 - accuracy: 0.4160 - val_loss: 1.1030 - val_accuracy: 0.4600\n",
      "Epoch 10/38\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.2518 - accuracy: 0.4210 - val_loss: 1.3963 - val_accuracy: 0.3733\n",
      "Epoch 11/38\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.2295 - accuracy: 0.4143 - val_loss: 0.9451 - val_accuracy: 0.4467\n",
      "Epoch 12/38\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.1808 - accuracy: 0.4493 - val_loss: 1.1516 - val_accuracy: 0.4333\n",
      "Epoch 13/38\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.1739 - accuracy: 0.4476 - val_loss: 0.8104 - val_accuracy: 0.4667\n",
      "Epoch 14/38\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1442 - accuracy: 0.4842 - val_loss: 1.4106 - val_accuracy: 0.4800\n",
      "Epoch 15/38\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1443 - accuracy: 0.4925 - val_loss: 1.0355 - val_accuracy: 0.4333\n",
      "Epoch 16/38\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.1965 - accuracy: 0.4958 - val_loss: 1.5396 - val_accuracy: 0.4867\n",
      "Epoch 17/38\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.1756 - accuracy: 0.4576 - val_loss: 1.1560 - val_accuracy: 0.4667\n",
      "Epoch 18/38\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1162 - accuracy: 0.4825 - val_loss: 1.3980 - val_accuracy: 0.5000\n",
      "Epoch 19/38\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0940 - accuracy: 0.5241 - val_loss: 1.1187 - val_accuracy: 0.5133\n",
      "Epoch 20/38\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0877 - accuracy: 0.4842 - val_loss: 0.9421 - val_accuracy: 0.4867\n",
      "Epoch 21/38\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.0426 - accuracy: 0.5424 - val_loss: 1.0202 - val_accuracy: 0.4933\n",
      "Epoch 22/38\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.0998 - accuracy: 0.5225 - val_loss: 1.3672 - val_accuracy: 0.4867\n",
      "Epoch 23/38\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.0854 - accuracy: 0.5141 - val_loss: 0.8182 - val_accuracy: 0.5133\n",
      "Epoch 24/38\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0863 - accuracy: 0.5208 - val_loss: 0.9338 - val_accuracy: 0.5133\n",
      "Epoch 25/38\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.0578 - accuracy: 0.5225 - val_loss: 1.2553 - val_accuracy: 0.5267\n",
      "Epoch 26/38\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0597 - accuracy: 0.5324 - val_loss: 1.1225 - val_accuracy: 0.4933\n",
      "Epoch 27/38\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.0630 - accuracy: 0.5374 - val_loss: 1.2356 - val_accuracy: 0.5133\n",
      "Epoch 28/38\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.0386 - accuracy: 0.5291 - val_loss: 1.2817 - val_accuracy: 0.4933\n",
      "Epoch 29/38\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.0114 - accuracy: 0.5574 - val_loss: 0.9215 - val_accuracy: 0.5133\n",
      "Epoch 30/38\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.9844 - accuracy: 0.5674 - val_loss: 0.4915 - val_accuracy: 0.5133\n",
      "Epoch 31/38\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.9604 - accuracy: 0.5674 - val_loss: 1.4781 - val_accuracy: 0.5200\n",
      "Epoch 32/38\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.9677 - accuracy: 0.5774 - val_loss: 0.5665 - val_accuracy: 0.4533\n",
      "Epoch 33/38\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0319 - accuracy: 0.5408 - val_loss: 1.1449 - val_accuracy: 0.5200\n",
      "Epoch 34/38\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.0063 - accuracy: 0.5674 - val_loss: 1.7249 - val_accuracy: 0.5333\n",
      "Epoch 35/38\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.0691 - accuracy: 0.5724 - val_loss: 0.5683 - val_accuracy: 0.4600\n",
      "Epoch 36/38\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1286 - accuracy: 0.4942 - val_loss: 0.8715 - val_accuracy: 0.4533\n",
      "Epoch 37/38\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0440 - accuracy: 0.5241 - val_loss: 0.8600 - val_accuracy: 0.4933\n",
      "Epoch 38/38\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.9772 - accuracy: 0.5707 - val_loss: 0.5662 - val_accuracy: 0.5133\n",
      "\n",
      "Model accuracy: 51.33%\n",
      "\n",
      "learning rate: 4.7e-03\n",
      "epochs       : 93\n",
      "Epoch 1/93\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.3437 - accuracy: 0.3594 - val_loss: 1.1406 - val_accuracy: 0.3667\n",
      "Epoch 2/93\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 1.3233 - accuracy: 0.3960 - val_loss: 1.3660 - val_accuracy: 0.3667\n",
      "Epoch 3/93\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.3052 - accuracy: 0.3960 - val_loss: 0.9979 - val_accuracy: 0.3667\n",
      "Epoch 4/93\n",
      "26/26 [==============================] - 2s 68ms/step - loss: 1.3298 - accuracy: 0.3960 - val_loss: 1.2933 - val_accuracy: 0.3667\n",
      "Epoch 5/93\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 1.2976 - accuracy: 0.3960 - val_loss: 1.2058 - val_accuracy: 0.3667\n",
      "Epoch 6/93\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 1.3061 - accuracy: 0.3960 - val_loss: 1.3388 - val_accuracy: 0.3667\n",
      "Epoch 7/93\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.2990 - accuracy: 0.3960 - val_loss: 1.0810 - val_accuracy: 0.3667\n",
      "Epoch 8/93\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.3209 - accuracy: 0.3960 - val_loss: 1.6488 - val_accuracy: 0.3667\n",
      "Epoch 9/93\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.2809 - accuracy: 0.3960 - val_loss: 1.4064 - val_accuracy: 0.3667\n",
      "Epoch 10/93\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 1.3057 - accuracy: 0.3960 - val_loss: 1.3033 - val_accuracy: 0.3667\n",
      "Epoch 11/93\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 1.2919 - accuracy: 0.3810 - val_loss: 1.3085 - val_accuracy: 0.3667\n",
      "Epoch 12/93\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 1.2654 - accuracy: 0.3960 - val_loss: 1.2653 - val_accuracy: 0.3667\n",
      "Epoch 13/93\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.3201 - accuracy: 0.3977 - val_loss: 1.4016 - val_accuracy: 0.3733\n",
      "Epoch 14/93\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 1.2349 - accuracy: 0.4276 - val_loss: 1.3632 - val_accuracy: 0.4533\n",
      "Epoch 15/93\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 1.2825 - accuracy: 0.4393 - val_loss: 1.4729 - val_accuracy: 0.4000\n",
      "Epoch 16/93\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.2403 - accuracy: 0.4010 - val_loss: 1.2768 - val_accuracy: 0.3667\n",
      "Epoch 17/93\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.2069 - accuracy: 0.4126 - val_loss: 1.4338 - val_accuracy: 0.4533\n",
      "Epoch 18/93\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.2314 - accuracy: 0.4376 - val_loss: 1.1603 - val_accuracy: 0.4467\n",
      "Epoch 19/93\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.1910 - accuracy: 0.4576 - val_loss: 1.2015 - val_accuracy: 0.4533\n",
      "Epoch 20/93\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1424 - accuracy: 0.4725 - val_loss: 1.5810 - val_accuracy: 0.4600\n",
      "Epoch 21/93\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1405 - accuracy: 0.4925 - val_loss: 1.3882 - val_accuracy: 0.5067\n",
      "Epoch 22/93\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1256 - accuracy: 0.4775 - val_loss: 1.1968 - val_accuracy: 0.5067\n",
      "Epoch 23/93\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1091 - accuracy: 0.5108 - val_loss: 1.3376 - val_accuracy: 0.5067\n",
      "Epoch 24/93\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1564 - accuracy: 0.4842 - val_loss: 1.0029 - val_accuracy: 0.4867\n",
      "Epoch 25/93\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1873 - accuracy: 0.4326 - val_loss: 1.0054 - val_accuracy: 0.5000\n",
      "Epoch 26/93\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1049 - accuracy: 0.4842 - val_loss: 1.1667 - val_accuracy: 0.4467\n",
      "Epoch 27/93\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.1395 - accuracy: 0.4975 - val_loss: 1.5881 - val_accuracy: 0.4467\n",
      "Epoch 28/93\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.1482 - accuracy: 0.5025 - val_loss: 0.7380 - val_accuracy: 0.5067\n",
      "Epoch 29/93\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.1065 - accuracy: 0.5075 - val_loss: 1.2808 - val_accuracy: 0.4400\n",
      "Epoch 30/93\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.0937 - accuracy: 0.4759 - val_loss: 1.2527 - val_accuracy: 0.4733\n",
      "Epoch 31/93\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0730 - accuracy: 0.5058 - val_loss: 1.0933 - val_accuracy: 0.5000\n",
      "Epoch 32/93\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 1.1020 - accuracy: 0.4992 - val_loss: 1.2198 - val_accuracy: 0.5200\n",
      "Epoch 33/93\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 1.0322 - accuracy: 0.5158 - val_loss: 0.7829 - val_accuracy: 0.4800\n",
      "Epoch 34/93\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.0471 - accuracy: 0.5208 - val_loss: 1.3316 - val_accuracy: 0.4933\n",
      "Epoch 35/93\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.0506 - accuracy: 0.4892 - val_loss: 1.6244 - val_accuracy: 0.5133\n",
      "Epoch 36/93\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 1.0176 - accuracy: 0.5275 - val_loss: 1.0304 - val_accuracy: 0.4733\n",
      "Epoch 37/93\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 1.0479 - accuracy: 0.5092 - val_loss: 1.3308 - val_accuracy: 0.4933\n",
      "Epoch 38/93\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 1.1557 - accuracy: 0.4958 - val_loss: 1.0582 - val_accuracy: 0.4933\n",
      "Epoch 39/93\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 1.0996 - accuracy: 0.4659 - val_loss: 0.7335 - val_accuracy: 0.5467\n",
      "Epoch 40/93\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.0576 - accuracy: 0.5275 - val_loss: 1.3850 - val_accuracy: 0.5733\n",
      "Epoch 41/93\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.0909 - accuracy: 0.5042 - val_loss: 1.3174 - val_accuracy: 0.5067\n",
      "Epoch 42/93\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 1.0142 - accuracy: 0.5474 - val_loss: 1.0643 - val_accuracy: 0.5133\n",
      "Epoch 43/93\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0194 - accuracy: 0.5324 - val_loss: 1.3311 - val_accuracy: 0.4867\n",
      "Epoch 44/93\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2040 - accuracy: 0.4859 - val_loss: 0.9093 - val_accuracy: 0.4467\n",
      "Epoch 45/93\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.1524 - accuracy: 0.4942 - val_loss: 1.3516 - val_accuracy: 0.4667\n",
      "Epoch 46/93\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.0650 - accuracy: 0.5391 - val_loss: 1.5235 - val_accuracy: 0.4800\n",
      "Epoch 47/93\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.1404 - accuracy: 0.4958 - val_loss: 0.8810 - val_accuracy: 0.4867\n",
      "Epoch 48/93\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.1131 - accuracy: 0.5125 - val_loss: 1.3292 - val_accuracy: 0.4800\n",
      "Epoch 49/93\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 1.1043 - accuracy: 0.5391 - val_loss: 1.2000 - val_accuracy: 0.4400\n",
      "Epoch 50/93\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 1.0526 - accuracy: 0.5524 - val_loss: 1.0341 - val_accuracy: 0.4800\n",
      "Epoch 51/93\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 1.0278 - accuracy: 0.5391 - val_loss: 1.5353 - val_accuracy: 0.4867\n",
      "Epoch 52/93\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.0126 - accuracy: 0.5208 - val_loss: 0.9662 - val_accuracy: 0.5600\n",
      "Epoch 53/93\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.9776 - accuracy: 0.5557 - val_loss: 1.2780 - val_accuracy: 0.5000\n",
      "Epoch 54/93\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.9698 - accuracy: 0.5790 - val_loss: 1.5381 - val_accuracy: 0.5133\n",
      "Epoch 55/93\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.9697 - accuracy: 0.5541 - val_loss: 1.4773 - val_accuracy: 0.5000\n",
      "Epoch 56/93\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 1.0261 - accuracy: 0.5724 - val_loss: 0.7310 - val_accuracy: 0.5467\n",
      "Epoch 57/93\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.9712 - accuracy: 0.5957 - val_loss: 0.9462 - val_accuracy: 0.5133\n",
      "Epoch 58/93\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.9252 - accuracy: 0.5674 - val_loss: 1.8141 - val_accuracy: 0.4800\n",
      "Epoch 59/93\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0646 - accuracy: 0.5474 - val_loss: 1.0858 - val_accuracy: 0.5133\n",
      "Epoch 60/93\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.9699 - accuracy: 0.5391 - val_loss: 0.9957 - val_accuracy: 0.5200\n",
      "Epoch 61/93\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.9472 - accuracy: 0.5740 - val_loss: 1.1797 - val_accuracy: 0.5267\n",
      "Epoch 62/93\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.9183 - accuracy: 0.5940 - val_loss: 1.3850 - val_accuracy: 0.5000\n",
      "Epoch 63/93\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.9590 - accuracy: 0.6190 - val_loss: 0.9337 - val_accuracy: 0.5533\n",
      "Epoch 64/93\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.8935 - accuracy: 0.6057 - val_loss: 0.7288 - val_accuracy: 0.5200\n",
      "Epoch 65/93\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.8643 - accuracy: 0.6256 - val_loss: 0.9436 - val_accuracy: 0.4867\n",
      "Epoch 66/93\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.8289 - accuracy: 0.6522 - val_loss: 0.5405 - val_accuracy: 0.5733\n",
      "Epoch 67/93\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.9022 - accuracy: 0.6506 - val_loss: 1.0804 - val_accuracy: 0.5267\n",
      "Epoch 68/93\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.8698 - accuracy: 0.6389 - val_loss: 1.1783 - val_accuracy: 0.5200\n",
      "Epoch 69/93\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.0235 - accuracy: 0.5624 - val_loss: 1.0054 - val_accuracy: 0.5533\n",
      "Epoch 70/93\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.9634 - accuracy: 0.5624 - val_loss: 1.2920 - val_accuracy: 0.4867\n",
      "Epoch 71/93\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.9393 - accuracy: 0.5940 - val_loss: 1.3358 - val_accuracy: 0.5533\n",
      "Epoch 72/93\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.8860 - accuracy: 0.6190 - val_loss: 1.0371 - val_accuracy: 0.5600\n",
      "Epoch 73/93\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.8786 - accuracy: 0.6023 - val_loss: 1.1220 - val_accuracy: 0.5267\n",
      "Epoch 74/93\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.8304 - accuracy: 0.6506 - val_loss: 1.3253 - val_accuracy: 0.5400\n",
      "Epoch 75/93\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.8259 - accuracy: 0.6672 - val_loss: 0.8763 - val_accuracy: 0.5533\n",
      "Epoch 76/93\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.7905 - accuracy: 0.6789 - val_loss: 1.8427 - val_accuracy: 0.3933\n",
      "Epoch 77/93\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.0343 - accuracy: 0.6256 - val_loss: 0.9217 - val_accuracy: 0.5667\n",
      "Epoch 78/93\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.8233 - accuracy: 0.6739 - val_loss: 1.2807 - val_accuracy: 0.5267\n",
      "Epoch 79/93\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.8376 - accuracy: 0.6489 - val_loss: 1.0835 - val_accuracy: 0.5667\n",
      "Epoch 80/93\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.8554 - accuracy: 0.6290 - val_loss: 1.1154 - val_accuracy: 0.5200\n",
      "Epoch 81/93\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.7981 - accuracy: 0.6805 - val_loss: 1.0566 - val_accuracy: 0.5133\n",
      "Epoch 82/93\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.8304 - accuracy: 0.6456 - val_loss: 0.9172 - val_accuracy: 0.5667\n",
      "Epoch 83/93\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.8018 - accuracy: 0.6656 - val_loss: 1.5211 - val_accuracy: 0.4933\n",
      "Epoch 84/93\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.8063 - accuracy: 0.6672 - val_loss: 1.1731 - val_accuracy: 0.5400\n",
      "Epoch 85/93\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.7159 - accuracy: 0.7238 - val_loss: 1.5213 - val_accuracy: 0.6000\n",
      "Epoch 86/93\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.7831 - accuracy: 0.6905 - val_loss: 0.8306 - val_accuracy: 0.5467\n",
      "Epoch 87/93\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.7317 - accuracy: 0.7338 - val_loss: 1.7572 - val_accuracy: 0.4867\n",
      "Epoch 88/93\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7641 - accuracy: 0.6622 - val_loss: 0.8978 - val_accuracy: 0.5933\n",
      "Epoch 89/93\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6462 - accuracy: 0.7504 - val_loss: 1.6764 - val_accuracy: 0.5933\n",
      "Epoch 90/93\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.6274 - accuracy: 0.7654 - val_loss: 1.4263 - val_accuracy: 0.5600\n",
      "Epoch 91/93\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 0.5923 - accuracy: 0.7671 - val_loss: 0.3437 - val_accuracy: 0.5400\n",
      "Epoch 92/93\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6137 - accuracy: 0.7504 - val_loss: 1.2468 - val_accuracy: 0.5267\n",
      "Epoch 93/93\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6590 - accuracy: 0.7304 - val_loss: 0.6764 - val_accuracy: 0.5667\n",
      "\n",
      "Model accuracy: 56.67%\n",
      "\n",
      "learning rate: 1.9e-03\n",
      "epochs       : 54\n",
      "Epoch 1/54\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.3246 - accuracy: 0.3478 - val_loss: 1.2699 - val_accuracy: 0.3667\n",
      "Epoch 2/54\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.2988 - accuracy: 0.3960 - val_loss: 1.1414 - val_accuracy: 0.3667\n",
      "Epoch 3/54\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.2920 - accuracy: 0.3960 - val_loss: 1.6140 - val_accuracy: 0.3667\n",
      "Epoch 4/54\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 1.2926 - accuracy: 0.3577 - val_loss: 1.3403 - val_accuracy: 0.3667\n",
      "Epoch 5/54\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.2709 - accuracy: 0.4027 - val_loss: 1.4523 - val_accuracy: 0.3667\n",
      "Epoch 6/54\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 1.2705 - accuracy: 0.3977 - val_loss: 1.0474 - val_accuracy: 0.4000\n",
      "Epoch 7/54\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.2511 - accuracy: 0.4110 - val_loss: 1.1630 - val_accuracy: 0.4200\n",
      "Epoch 8/54\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.2116 - accuracy: 0.4542 - val_loss: 1.2846 - val_accuracy: 0.4667\n",
      "Epoch 9/54\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.2449 - accuracy: 0.4243 - val_loss: 1.4882 - val_accuracy: 0.3200\n",
      "Epoch 10/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.3330 - accuracy: 0.4276 - val_loss: 1.1760 - val_accuracy: 0.3667\n",
      "Epoch 11/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2488 - accuracy: 0.4160 - val_loss: 0.8518 - val_accuracy: 0.4200\n",
      "Epoch 12/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2392 - accuracy: 0.4559 - val_loss: 1.3933 - val_accuracy: 0.4467\n",
      "Epoch 13/54\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.2401 - accuracy: 0.4060 - val_loss: 1.1905 - val_accuracy: 0.3867\n",
      "Epoch 14/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1806 - accuracy: 0.4243 - val_loss: 1.3818 - val_accuracy: 0.4800\n",
      "Epoch 15/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1771 - accuracy: 0.4459 - val_loss: 1.2898 - val_accuracy: 0.4667\n",
      "Epoch 16/54\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1429 - accuracy: 0.4659 - val_loss: 1.0882 - val_accuracy: 0.4733\n",
      "Epoch 17/54\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1368 - accuracy: 0.4925 - val_loss: 0.9728 - val_accuracy: 0.4667\n",
      "Epoch 18/54\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1272 - accuracy: 0.4742 - val_loss: 1.7283 - val_accuracy: 0.4467\n",
      "Epoch 19/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2062 - accuracy: 0.4260 - val_loss: 1.3414 - val_accuracy: 0.4200\n",
      "Epoch 20/54\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1888 - accuracy: 0.4309 - val_loss: 0.7234 - val_accuracy: 0.4467\n",
      "Epoch 21/54\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.2118 - accuracy: 0.4409 - val_loss: 0.8899 - val_accuracy: 0.4533\n",
      "Epoch 22/54\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.2661 - accuracy: 0.4576 - val_loss: 0.9450 - val_accuracy: 0.4533\n",
      "Epoch 23/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1894 - accuracy: 0.4343 - val_loss: 0.8486 - val_accuracy: 0.4667\n",
      "Epoch 24/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1750 - accuracy: 0.4193 - val_loss: 1.6905 - val_accuracy: 0.4000\n",
      "Epoch 25/54\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1464 - accuracy: 0.4742 - val_loss: 1.1266 - val_accuracy: 0.4867\n",
      "Epoch 26/54\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1210 - accuracy: 0.4859 - val_loss: 1.5037 - val_accuracy: 0.5067\n",
      "Epoch 27/54\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1034 - accuracy: 0.4975 - val_loss: 0.6165 - val_accuracy: 0.5200\n",
      "Epoch 28/54\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0812 - accuracy: 0.5092 - val_loss: 1.3338 - val_accuracy: 0.4600\n",
      "Epoch 29/54\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.1369 - accuracy: 0.4958 - val_loss: 0.8932 - val_accuracy: 0.4933\n",
      "Epoch 30/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0834 - accuracy: 0.5208 - val_loss: 1.0817 - val_accuracy: 0.5000\n",
      "Epoch 31/54\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.0617 - accuracy: 0.5208 - val_loss: 1.1436 - val_accuracy: 0.5267\n",
      "Epoch 32/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0191 - accuracy: 0.5408 - val_loss: 0.9225 - val_accuracy: 0.5133\n",
      "Epoch 33/54\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.1291 - accuracy: 0.5108 - val_loss: 0.8691 - val_accuracy: 0.4933\n",
      "Epoch 34/54\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.0351 - accuracy: 0.5158 - val_loss: 0.7360 - val_accuracy: 0.5133\n",
      "Epoch 35/54\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0023 - accuracy: 0.5557 - val_loss: 0.8006 - val_accuracy: 0.5333\n",
      "Epoch 36/54\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9766 - accuracy: 0.5491 - val_loss: 0.9741 - val_accuracy: 0.4667\n",
      "Epoch 37/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.9860 - accuracy: 0.5624 - val_loss: 1.3072 - val_accuracy: 0.5333\n",
      "Epoch 38/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0620 - accuracy: 0.5424 - val_loss: 0.8201 - val_accuracy: 0.5133\n",
      "Epoch 39/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.9685 - accuracy: 0.5591 - val_loss: 1.0044 - val_accuracy: 0.5333\n",
      "Epoch 40/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.9626 - accuracy: 0.5724 - val_loss: 0.5962 - val_accuracy: 0.5400\n",
      "Epoch 41/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.9492 - accuracy: 0.5923 - val_loss: 0.9715 - val_accuracy: 0.5667\n",
      "Epoch 42/54\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.9887 - accuracy: 0.5657 - val_loss: 0.6375 - val_accuracy: 0.5267\n",
      "Epoch 43/54\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9314 - accuracy: 0.6007 - val_loss: 1.0839 - val_accuracy: 0.6000\n",
      "Epoch 44/54\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9720 - accuracy: 0.5707 - val_loss: 1.2336 - val_accuracy: 0.4667\n",
      "Epoch 45/54\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9503 - accuracy: 0.5740 - val_loss: 6.4481 - val_accuracy: 0.5000\n",
      "Epoch 46/54\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9185 - accuracy: 0.5774 - val_loss: 0.6000 - val_accuracy: 0.5067\n",
      "Epoch 47/54\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9198 - accuracy: 0.5957 - val_loss: 1.2323 - val_accuracy: 0.5733\n",
      "Epoch 48/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.9580 - accuracy: 0.6173 - val_loss: 0.8661 - val_accuracy: 0.5067\n",
      "Epoch 49/54\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9634 - accuracy: 0.5957 - val_loss: 0.8757 - val_accuracy: 0.5067\n",
      "Epoch 50/54\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.8719 - accuracy: 0.6190 - val_loss: 5.6673 - val_accuracy: 0.5267\n",
      "Epoch 51/54\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.8789 - accuracy: 0.6173 - val_loss: 0.8738 - val_accuracy: 0.5200\n",
      "Epoch 52/54\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.8185 - accuracy: 0.6572 - val_loss: 1.8001 - val_accuracy: 0.4933\n",
      "Epoch 53/54\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.0135 - accuracy: 0.5857 - val_loss: 1.0964 - val_accuracy: 0.5200\n",
      "Epoch 54/54\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 1.1103 - accuracy: 0.5458 - val_loss: 1.2063 - val_accuracy: 0.5400\n",
      "\n",
      "Model accuracy: 54.00%\n",
      "\n",
      "learning rate: 5.0e-01\n",
      "epochs       : 82\n",
      "Epoch 1/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.3257 - accuracy: 0.3361 - val_loss: 1.7901 - val_accuracy: 0.3200\n",
      "Epoch 2/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.3186 - accuracy: 0.3710 - val_loss: 1.3435 - val_accuracy: 0.3667\n",
      "Epoch 3/82\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.2916 - accuracy: 0.3960 - val_loss: 1.4677 - val_accuracy: 0.3667\n",
      "Epoch 4/82\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.2945 - accuracy: 0.3960 - val_loss: 1.3420 - val_accuracy: 0.3667\n",
      "Epoch 5/82\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 1.3014 - accuracy: 0.3960 - val_loss: 1.2636 - val_accuracy: 0.3667\n",
      "Epoch 6/82\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.3174 - accuracy: 0.3960 - val_loss: 1.2478 - val_accuracy: 0.3667\n",
      "Epoch 7/82\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.2528 - accuracy: 0.3977 - val_loss: 1.2284 - val_accuracy: 0.3667\n",
      "Epoch 8/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.2467 - accuracy: 0.3877 - val_loss: 1.1921 - val_accuracy: 0.3800\n",
      "Epoch 9/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.2792 - accuracy: 0.3993 - val_loss: 1.1800 - val_accuracy: 0.3667\n",
      "Epoch 10/82\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.2527 - accuracy: 0.3960 - val_loss: 1.5855 - val_accuracy: 0.3733\n",
      "Epoch 11/82\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2103 - accuracy: 0.4043 - val_loss: 1.4139 - val_accuracy: 0.3867\n",
      "Epoch 12/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.2376 - accuracy: 0.4193 - val_loss: 1.2939 - val_accuracy: 0.3667\n",
      "Epoch 13/82\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.1861 - accuracy: 0.4343 - val_loss: 0.9976 - val_accuracy: 0.4933\n",
      "Epoch 14/82\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1787 - accuracy: 0.4659 - val_loss: 0.9190 - val_accuracy: 0.4667\n",
      "Epoch 15/82\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.1900 - accuracy: 0.4642 - val_loss: 1.1959 - val_accuracy: 0.4667\n",
      "Epoch 16/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1718 - accuracy: 0.4709 - val_loss: 1.2105 - val_accuracy: 0.4067\n",
      "Epoch 17/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.2359 - accuracy: 0.4060 - val_loss: 1.6029 - val_accuracy: 0.3800\n",
      "Epoch 18/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1815 - accuracy: 0.4676 - val_loss: 1.5038 - val_accuracy: 0.4600\n",
      "Epoch 19/82\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1478 - accuracy: 0.4775 - val_loss: 1.0630 - val_accuracy: 0.4800\n",
      "Epoch 20/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1502 - accuracy: 0.4875 - val_loss: 2.4738 - val_accuracy: 0.4467\n",
      "Epoch 21/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1702 - accuracy: 0.4676 - val_loss: 0.7450 - val_accuracy: 0.4667\n",
      "Epoch 22/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1799 - accuracy: 0.4393 - val_loss: 1.4287 - val_accuracy: 0.4733\n",
      "Epoch 23/82\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.1663 - accuracy: 0.4609 - val_loss: 1.3323 - val_accuracy: 0.5133\n",
      "Epoch 24/82\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.1094 - accuracy: 0.4975 - val_loss: 0.5687 - val_accuracy: 0.5133\n",
      "Epoch 25/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1132 - accuracy: 0.5042 - val_loss: 0.9495 - val_accuracy: 0.5000\n",
      "Epoch 26/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.2246 - accuracy: 0.4842 - val_loss: 1.8869 - val_accuracy: 0.4733\n",
      "Epoch 27/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1181 - accuracy: 0.4859 - val_loss: 0.9377 - val_accuracy: 0.4667\n",
      "Epoch 28/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1247 - accuracy: 0.5025 - val_loss: 0.9383 - val_accuracy: 0.4867\n",
      "Epoch 29/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.0910 - accuracy: 0.4942 - val_loss: 1.4012 - val_accuracy: 0.4467\n",
      "Epoch 30/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.0296 - accuracy: 0.5208 - val_loss: 0.7529 - val_accuracy: 0.4733\n",
      "Epoch 31/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0276 - accuracy: 0.5408 - val_loss: 1.8077 - val_accuracy: 0.4733\n",
      "Epoch 32/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0641 - accuracy: 0.5108 - val_loss: 0.9806 - val_accuracy: 0.4133\n",
      "Epoch 33/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.0188 - accuracy: 0.5524 - val_loss: 1.5769 - val_accuracy: 0.4867\n",
      "Epoch 34/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0430 - accuracy: 0.5474 - val_loss: 0.8897 - val_accuracy: 0.4933\n",
      "Epoch 35/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.0623 - accuracy: 0.5025 - val_loss: 1.1039 - val_accuracy: 0.5133\n",
      "Epoch 36/82\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.0165 - accuracy: 0.5591 - val_loss: 0.7243 - val_accuracy: 0.4867\n",
      "Epoch 37/82\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 1.0172 - accuracy: 0.5707 - val_loss: 1.1524 - val_accuracy: 0.4267\n",
      "Epoch 38/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.0427 - accuracy: 0.5241 - val_loss: 0.8903 - val_accuracy: 0.5000\n",
      "Epoch 39/82\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0589 - accuracy: 0.5358 - val_loss: 0.9050 - val_accuracy: 0.5200\n",
      "Epoch 40/82\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0529 - accuracy: 0.5324 - val_loss: 1.2893 - val_accuracy: 0.5133\n",
      "Epoch 41/82\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.9920 - accuracy: 0.5840 - val_loss: 0.6022 - val_accuracy: 0.5200\n",
      "Epoch 42/82\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.9585 - accuracy: 0.5691 - val_loss: 0.7941 - val_accuracy: 0.5200\n",
      "Epoch 43/82\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.0473 - accuracy: 0.5557 - val_loss: 1.0535 - val_accuracy: 0.4467\n",
      "Epoch 44/82\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.9628 - accuracy: 0.5541 - val_loss: 1.1953 - val_accuracy: 0.5733\n",
      "Epoch 45/82\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.9054 - accuracy: 0.6057 - val_loss: 1.4255 - val_accuracy: 0.5200\n",
      "Epoch 46/82\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.9122 - accuracy: 0.6090 - val_loss: 1.1091 - val_accuracy: 0.5467\n",
      "Epoch 47/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.8684 - accuracy: 0.6173 - val_loss: 1.7063 - val_accuracy: 0.5000\n",
      "Epoch 48/82\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.9958 - accuracy: 0.5541 - val_loss: 1.5272 - val_accuracy: 0.5533\n",
      "Epoch 49/82\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.8801 - accuracy: 0.6223 - val_loss: 0.7336 - val_accuracy: 0.5200\n",
      "Epoch 50/82\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.8509 - accuracy: 0.6423 - val_loss: 1.0785 - val_accuracy: 0.5600\n",
      "Epoch 51/82\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.8781 - accuracy: 0.6156 - val_loss: 1.1611 - val_accuracy: 0.5600\n",
      "Epoch 52/82\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.9134 - accuracy: 0.5790 - val_loss: 0.6445 - val_accuracy: 0.5133\n",
      "Epoch 53/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.8483 - accuracy: 0.6156 - val_loss: 0.5315 - val_accuracy: 0.5467\n",
      "Epoch 54/82\n",
      "26/26 [==============================] - 3s 104ms/step - loss: 0.8727 - accuracy: 0.6373 - val_loss: 1.2668 - val_accuracy: 0.5600\n",
      "Epoch 55/82\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.8259 - accuracy: 0.6456 - val_loss: 1.0835 - val_accuracy: 0.5867\n",
      "Epoch 56/82\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.8359 - accuracy: 0.6689 - val_loss: 1.2386 - val_accuracy: 0.6000\n",
      "Epoch 57/82\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.7358 - accuracy: 0.7038 - val_loss: 1.2007 - val_accuracy: 0.5933\n",
      "Epoch 58/82\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.7136 - accuracy: 0.7022 - val_loss: 0.2354 - val_accuracy: 0.5933\n",
      "Epoch 59/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6941 - accuracy: 0.7072 - val_loss: 0.8909 - val_accuracy: 0.5800\n",
      "Epoch 60/82\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6881 - accuracy: 0.6905 - val_loss: 3.5554 - val_accuracy: 0.5600\n",
      "Epoch 61/82\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.7137 - accuracy: 0.7022 - val_loss: 0.6156 - val_accuracy: 0.5267\n",
      "Epoch 62/82\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.8620 - accuracy: 0.6705 - val_loss: 0.9252 - val_accuracy: 0.4400\n",
      "Epoch 63/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.8841 - accuracy: 0.6106 - val_loss: 3.5478 - val_accuracy: 0.5733\n",
      "Epoch 64/82\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.7072 - accuracy: 0.7105 - val_loss: 1.3304 - val_accuracy: 0.5667\n",
      "Epoch 65/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6615 - accuracy: 0.7321 - val_loss: 0.7735 - val_accuracy: 0.5733\n",
      "Epoch 66/82\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6116 - accuracy: 0.7371 - val_loss: 0.9950 - val_accuracy: 0.5400\n",
      "Epoch 67/82\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6103 - accuracy: 0.7737 - val_loss: 1.7650 - val_accuracy: 0.5000\n",
      "Epoch 68/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6213 - accuracy: 0.7255 - val_loss: 1.1110 - val_accuracy: 0.5667\n",
      "Epoch 69/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.5763 - accuracy: 0.7537 - val_loss: 0.6749 - val_accuracy: 0.5667\n",
      "Epoch 70/82\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.5083 - accuracy: 0.7903 - val_loss: 0.6736 - val_accuracy: 0.5533\n",
      "Epoch 71/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.5855 - accuracy: 0.7770 - val_loss: 4.0320 - val_accuracy: 0.5467\n",
      "Epoch 72/82\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6036 - accuracy: 0.7537 - val_loss: 0.5869 - val_accuracy: 0.4933\n",
      "Epoch 73/82\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.4826 - accuracy: 0.8153 - val_loss: 0.8226 - val_accuracy: 0.4867\n",
      "Epoch 74/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.5096 - accuracy: 0.7920 - val_loss: 1.7170 - val_accuracy: 0.5267\n",
      "Epoch 75/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.3855 - accuracy: 0.8619 - val_loss: 0.8156 - val_accuracy: 0.5200\n",
      "Epoch 76/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.3787 - accuracy: 0.8453 - val_loss: 1.0253 - val_accuracy: 0.5333\n",
      "Epoch 77/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.4337 - accuracy: 0.8336 - val_loss: 1.9083 - val_accuracy: 0.5667\n",
      "Epoch 78/82\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.3130 - accuracy: 0.8769 - val_loss: 0.2809 - val_accuracy: 0.5133\n",
      "Epoch 79/82\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.5635 - accuracy: 0.8153 - val_loss: 0.9841 - val_accuracy: 0.5533\n",
      "Epoch 80/82\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.4524 - accuracy: 0.8220 - val_loss: 5.1455 - val_accuracy: 0.5467\n",
      "Epoch 81/82\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.5324 - accuracy: 0.7970 - val_loss: 0.5268 - val_accuracy: 0.5533\n",
      "Epoch 82/82\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.3070 - accuracy: 0.8952 - val_loss: 1.1814 - val_accuracy: 0.5533\n",
      "\n",
      "Model accuracy: 55.33%\n",
      "\n",
      "learning rate: 1.7e-02\n",
      "epochs       : 100\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.3087 - accuracy: 0.3827 - val_loss: 1.4275 - val_accuracy: 0.3667\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.3237 - accuracy: 0.3960 - val_loss: 1.1499 - val_accuracy: 0.4333\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.3272 - accuracy: 0.3760 - val_loss: 1.2394 - val_accuracy: 0.3667\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.3000 - accuracy: 0.3960 - val_loss: 1.1992 - val_accuracy: 0.3667\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.3165 - accuracy: 0.3960 - val_loss: 1.3972 - val_accuracy: 0.3667\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2523 - accuracy: 0.4060 - val_loss: 1.0151 - val_accuracy: 0.3667\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.2834 - accuracy: 0.3527 - val_loss: 1.6271 - val_accuracy: 0.3667\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.2484 - accuracy: 0.3960 - val_loss: 1.4947 - val_accuracy: 0.3667\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2914 - accuracy: 0.4027 - val_loss: 1.2315 - val_accuracy: 0.4333\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.2426 - accuracy: 0.3494 - val_loss: 1.2924 - val_accuracy: 0.3667\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.2085 - accuracy: 0.4126 - val_loss: 1.2315 - val_accuracy: 0.4467\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2020 - accuracy: 0.4210 - val_loss: 1.2775 - val_accuracy: 0.4067\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1831 - accuracy: 0.4409 - val_loss: 1.3568 - val_accuracy: 0.4067\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1802 - accuracy: 0.4260 - val_loss: 1.2372 - val_accuracy: 0.4133\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2123 - accuracy: 0.4226 - val_loss: 1.2122 - val_accuracy: 0.3933\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.2020 - accuracy: 0.4077 - val_loss: 1.1729 - val_accuracy: 0.4800\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.2080 - accuracy: 0.4725 - val_loss: 2.0081 - val_accuracy: 0.4800\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1679 - accuracy: 0.4842 - val_loss: 1.1860 - val_accuracy: 0.4667\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1777 - accuracy: 0.4742 - val_loss: 1.3744 - val_accuracy: 0.4467\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.2236 - accuracy: 0.4176 - val_loss: 1.5251 - val_accuracy: 0.3600\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1608 - accuracy: 0.4592 - val_loss: 1.6201 - val_accuracy: 0.4533\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.1076 - accuracy: 0.4958 - val_loss: 0.8111 - val_accuracy: 0.4600\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 1.2476 - accuracy: 0.4443 - val_loss: 1.5910 - val_accuracy: 0.4200\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 1.2236 - accuracy: 0.4592 - val_loss: 0.9763 - val_accuracy: 0.4333\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 1.1690 - accuracy: 0.4393 - val_loss: 1.5277 - val_accuracy: 0.4733\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.1161 - accuracy: 0.5008 - val_loss: 1.0185 - val_accuracy: 0.4400\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.1636 - accuracy: 0.4676 - val_loss: 1.3534 - val_accuracy: 0.4800\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0976 - accuracy: 0.4875 - val_loss: 1.1716 - val_accuracy: 0.4800\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1407 - accuracy: 0.4493 - val_loss: 0.9247 - val_accuracy: 0.4733\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1208 - accuracy: 0.5025 - val_loss: 1.0323 - val_accuracy: 0.4467\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1648 - accuracy: 0.4526 - val_loss: 0.9968 - val_accuracy: 0.4600\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1097 - accuracy: 0.4809 - val_loss: 1.0038 - val_accuracy: 0.4400\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0803 - accuracy: 0.5191 - val_loss: 1.2306 - val_accuracy: 0.4800\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0791 - accuracy: 0.5291 - val_loss: 0.8514 - val_accuracy: 0.4400\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0614 - accuracy: 0.5324 - val_loss: 0.7642 - val_accuracy: 0.4867\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0122 - accuracy: 0.5541 - val_loss: 0.9692 - val_accuracy: 0.4733\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0234 - accuracy: 0.5591 - val_loss: 1.1206 - val_accuracy: 0.4800\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0016 - accuracy: 0.5524 - val_loss: 1.2791 - val_accuracy: 0.4800\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0473 - accuracy: 0.5458 - val_loss: 0.9130 - val_accuracy: 0.5133\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.0177 - accuracy: 0.5757 - val_loss: 1.3227 - val_accuracy: 0.4267\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0104 - accuracy: 0.5740 - val_loss: 0.7804 - val_accuracy: 0.5133\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9746 - accuracy: 0.5607 - val_loss: 0.5115 - val_accuracy: 0.5467\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9258 - accuracy: 0.6240 - val_loss: 0.9687 - val_accuracy: 0.4733\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.0287 - accuracy: 0.5324 - val_loss: 1.1567 - val_accuracy: 0.5533\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.9429 - accuracy: 0.6040 - val_loss: 1.2811 - val_accuracy: 0.5333\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9461 - accuracy: 0.5907 - val_loss: 1.1039 - val_accuracy: 0.5333\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9312 - accuracy: 0.6290 - val_loss: 1.0288 - val_accuracy: 0.5400\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.8814 - accuracy: 0.6206 - val_loss: 1.0138 - val_accuracy: 0.5067\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.8722 - accuracy: 0.6240 - val_loss: 1.3428 - val_accuracy: 0.5467\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9409 - accuracy: 0.6323 - val_loss: 1.6035 - val_accuracy: 0.4933\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.9149 - accuracy: 0.6123 - val_loss: 1.1552 - val_accuracy: 0.5200\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.9272 - accuracy: 0.6190 - val_loss: 0.4819 - val_accuracy: 0.4933\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.9051 - accuracy: 0.6256 - val_loss: 0.6509 - val_accuracy: 0.5267\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.8077 - accuracy: 0.6789 - val_loss: 0.5279 - val_accuracy: 0.5467\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0137 - accuracy: 0.5757 - val_loss: 0.6983 - val_accuracy: 0.5267\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.8378 - accuracy: 0.6323 - val_loss: 1.3476 - val_accuracy: 0.5667\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7635 - accuracy: 0.6905 - val_loss: 1.1323 - val_accuracy: 0.5267\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.8014 - accuracy: 0.6589 - val_loss: 1.1788 - val_accuracy: 0.5467\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7964 - accuracy: 0.6805 - val_loss: 1.1381 - val_accuracy: 0.5333\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7536 - accuracy: 0.6972 - val_loss: 0.7751 - val_accuracy: 0.5067\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.7847 - accuracy: 0.6572 - val_loss: 1.2859 - val_accuracy: 0.5333\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.7143 - accuracy: 0.7138 - val_loss: 1.8501 - val_accuracy: 0.5733\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.8146 - accuracy: 0.6872 - val_loss: 1.0095 - val_accuracy: 0.5933\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.8537 - accuracy: 0.6689 - val_loss: 0.9506 - val_accuracy: 0.4800\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.7564 - accuracy: 0.6988 - val_loss: 0.9266 - val_accuracy: 0.4933\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.8804 - accuracy: 0.6373 - val_loss: 1.7277 - val_accuracy: 0.5133\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6879 - accuracy: 0.7221 - val_loss: 0.7100 - val_accuracy: 0.5533\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.5986 - accuracy: 0.7754 - val_loss: 1.2011 - val_accuracy: 0.6000\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6073 - accuracy: 0.7621 - val_loss: 1.0346 - val_accuracy: 0.5733\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.5772 - accuracy: 0.7854 - val_loss: 2.2392 - val_accuracy: 0.5533\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.5850 - accuracy: 0.7554 - val_loss: 0.8253 - val_accuracy: 0.5867\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6260 - accuracy: 0.7488 - val_loss: 0.6277 - val_accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.5558 - accuracy: 0.7770 - val_loss: 1.8841 - val_accuracy: 0.5200\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.5523 - accuracy: 0.7870 - val_loss: 0.7888 - val_accuracy: 0.5733\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 0.7219 - accuracy: 0.7188 - val_loss: 1.2294 - val_accuracy: 0.5600\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.5795 - accuracy: 0.7654 - val_loss: 0.3802 - val_accuracy: 0.5733\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.5337 - accuracy: 0.8070 - val_loss: 2.7022 - val_accuracy: 0.4533\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.6582 - accuracy: 0.7388 - val_loss: 1.5910 - val_accuracy: 0.6200\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.4858 - accuracy: 0.8136 - val_loss: 1.2203 - val_accuracy: 0.6000\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.4513 - accuracy: 0.8270 - val_loss: 0.4168 - val_accuracy: 0.5533\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.3763 - accuracy: 0.8735 - val_loss: 0.6237 - val_accuracy: 0.5867\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.3950 - accuracy: 0.8569 - val_loss: 0.1273 - val_accuracy: 0.5533\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.4243 - accuracy: 0.8286 - val_loss: 0.7184 - val_accuracy: 0.5400\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.3074 - accuracy: 0.8869 - val_loss: 0.7735 - val_accuracy: 0.5667\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.3187 - accuracy: 0.8902 - val_loss: 1.9251 - val_accuracy: 0.5933\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.2758 - accuracy: 0.8968 - val_loss: 2.1404 - val_accuracy: 0.5467\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.3443 - accuracy: 0.8569 - val_loss: 0.5156 - val_accuracy: 0.5333\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.2894 - accuracy: 0.8918 - val_loss: 1.9766 - val_accuracy: 0.5533\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.2161 - accuracy: 0.9301 - val_loss: 0.5881 - val_accuracy: 0.5600\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.2021 - accuracy: 0.9501 - val_loss: 2.8336 - val_accuracy: 0.5467\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.4192 - accuracy: 0.8536 - val_loss: 0.7047 - val_accuracy: 0.5467\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.2472 - accuracy: 0.9151 - val_loss: 1.6923 - val_accuracy: 0.5667\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.1808 - accuracy: 0.9501 - val_loss: 1.3245 - val_accuracy: 0.5733\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.2271 - accuracy: 0.9185 - val_loss: 3.4945 - val_accuracy: 0.5267\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.4353 - accuracy: 0.8702 - val_loss: 1.4791 - val_accuracy: 0.4733\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.3872 - accuracy: 0.8519 - val_loss: 3.8649 - val_accuracy: 0.5600\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.1967 - accuracy: 0.9551 - val_loss: 0.6012 - val_accuracy: 0.5800\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.2322 - accuracy: 0.9251 - val_loss: 2.2519 - val_accuracy: 0.5600\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.1815 - accuracy: 0.9451 - val_loss: 0.2792 - val_accuracy: 0.5600\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.1107 - accuracy: 0.9834 - val_loss: 2.3924 - val_accuracy: 0.5867\n",
      "\n",
      "Model accuracy: 58.67%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(func=fitness,\n",
    "                                dimensions=dimensions,\n",
    "                                acq_func='EI', # Expected Improvement.\n",
    "                                n_calls=12,\n",
    "                                x0=default_parameters,\n",
    "                                random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20ab3574d48>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skopt.plots import plot_convergence, plot_objective, plot_evaluations\n",
    "plot_convergence(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_objective_2D(result=search_result,\n",
    "#                         dimension_name1='learning_rate',\n",
    "#                         dimension_name2='epochs',\n",
    "#                         levels=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_names = [\"learning_rate\", \"epochs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plot_objective(result=search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plot_evaluations(result=search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01733304007508762, 100]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = search_result.space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.5866666436195374, [0.01733304007508762, 100]),\n",
       " (-0.5666666626930237, [0.004699693600285314, 93]),\n",
       " (-0.5533333420753479, [0.4961796485117123, 82]),\n",
       " (-0.5400000214576721, [0.00036844068804921996, 62]),\n",
       " (-0.5400000214576721, [0.0019320752621429876, 54]),\n",
       " (-0.5400000214576721, [0.47609690039378916, 88]),\n",
       " (-0.5400000214576721, [0.9681085478045705, 95]),\n",
       " (-0.5333333611488342, [0.0008700690210600545, 74]),\n",
       " (-0.5133333206176758, [4.371417028022744e-05, 100]),\n",
       " (-0.5133333206176758, [0.0016491663656852536, 38]),\n",
       " (-0.5066666603088379, [0.000151511251231029, 52]),\n",
       " (-0.46000000834465027, [1e-05, 20])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(search_result.func_vals, search_result.x_iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_adam = keras.models.load_model(best_model)\n",
    "type(best_model_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 validated image filenames belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = fetch_images_dataframe(test_df, x_col=\"song\", y_col=\"artist\", directory=test_path,\n",
    "                                                           batch_size=batch_size, target_size=target_size, \n",
    "                                                            class_mode=\"categorical\", shuffle=False, seed=1, save_format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = best_model_adam.predict_generator(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(data={\"songs\": test_gen.filenames,\n",
    "                                   \"predictions\": preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {v:k for k,v in class_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[\"predictions\"] = pred_df[\"predictions\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>songs</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rock And Roll Music (Remastered 2009)-IRF6nmqc...</td>\n",
       "      <td>starr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good Morning Good Morning (Remastered 2009)-sj...</td>\n",
       "      <td>Lennon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You Never Give Me Your Money (2019 Mix)-W8uZje...</td>\n",
       "      <td>mccartney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Being For The Benefit Of Mr. Kite! (Remastered...</td>\n",
       "      <td>starr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mr Moonlight (Remastered 2009)-FZQ8nWZJrhA.png</td>\n",
       "      <td>Lennon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Pepperland Laid Waste (Remastered 2009)-JGauvW...</td>\n",
       "      <td>mccartney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Think For Yourself (Remastered 2009)-vtx5NTxeb...</td>\n",
       "      <td>starr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>You Can't Do That (Remastered 2009)-6PK21u7Yzm...</td>\n",
       "      <td>starr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Glass Onion (Remastered 2009)-2tSIZLuCKUI.png</td>\n",
       "      <td>Lennon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>The Beatles - Come Together-45cYwDMibGo.png</td>\n",
       "      <td>mccartney</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 songs predictions\n",
       "0    Rock And Roll Music (Remastered 2009)-IRF6nmqc...       starr\n",
       "1    Good Morning Good Morning (Remastered 2009)-sj...      Lennon\n",
       "2    You Never Give Me Your Money (2019 Mix)-W8uZje...   mccartney\n",
       "3    Being For The Benefit Of Mr. Kite! (Remastered...       starr\n",
       "4       Mr Moonlight (Remastered 2009)-FZQ8nWZJrhA.png      Lennon\n",
       "..                                                 ...         ...\n",
       "211  Pepperland Laid Waste (Remastered 2009)-JGauvW...   mccartney\n",
       "212  Think For Yourself (Remastered 2009)-vtx5NTxeb...       starr\n",
       "213  You Can't Do That (Remastered 2009)-6PK21u7Yzm...       starr\n",
       "214      Glass Onion (Remastered 2009)-2tSIZLuCKUI.png      Lennon\n",
       "215        The Beatles - Come Together-45cYwDMibGo.png   mccartney\n",
       "\n",
       "[216 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>songs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictions</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lennon</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harrison</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccartney</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starr</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             songs\n",
       "predictions       \n",
       "Lennon          55\n",
       "harrison        24\n",
       "mccartney      105\n",
       "starr           32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.groupby(\"predictions\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df.merge(test_df[[\"album\", \"song\"]], left_on=\"songs\",right_on=\"song\")\n",
    "pred_df.drop(\"song\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>songs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>album</th>\n",
       "      <th>predictions</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">AbbeyRoad</th>\n",
       "      <th>Lennon</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harrison</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccartney</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starr</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">BeatlesForSale</th>\n",
       "      <th>Lennon</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harrison</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccartney</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starr</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">HardDaysNight</th>\n",
       "      <th>Lennon</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harrison</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccartney</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starr</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Help!</th>\n",
       "      <th>Lennon</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harrison</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccartney</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">LetItBe</th>\n",
       "      <th>Lennon</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harrison</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccartney</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starr</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">MagicalMysteryTour</th>\n",
       "      <th>Lennon</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harrison</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccartney</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starr</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">PleasePleaseMe</th>\n",
       "      <th>Lennon</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harrison</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccartney</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starr</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Revolver</th>\n",
       "      <th>Lennon</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harrison</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccartney</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starr</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RubberSoul</th>\n",
       "      <th>harrison</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccartney</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starr</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SgtPepper</th>\n",
       "      <th>Lennon</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccartney</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starr</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">WhiteAlbum</th>\n",
       "      <th>Lennon</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harrison</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccartney</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starr</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">WithTheBeatles</th>\n",
       "      <th>Lennon</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harrison</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccartney</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starr</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">YellowSubmarine</th>\n",
       "      <th>Lennon</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccartney</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starr</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                songs\n",
       "album              predictions       \n",
       "AbbeyRoad          Lennon           8\n",
       "                   harrison         1\n",
       "                   mccartney       25\n",
       "                   starr            6\n",
       "BeatlesForSale     Lennon           4\n",
       "                   harrison         4\n",
       "                   mccartney        3\n",
       "                   starr            3\n",
       "HardDaysNight      Lennon           4\n",
       "                   harrison         2\n",
       "                   mccartney        6\n",
       "                   starr            1\n",
       "Help!              Lennon           3\n",
       "                   harrison         4\n",
       "                   mccartney        7\n",
       "LetItBe            Lennon           2\n",
       "                   harrison         3\n",
       "                   mccartney        4\n",
       "                   starr            3\n",
       "MagicalMysteryTour Lennon           5\n",
       "                   harrison         1\n",
       "                   mccartney        4\n",
       "                   starr            1\n",
       "PleasePleaseMe     Lennon           5\n",
       "                   harrison         1\n",
       "                   mccartney        5\n",
       "                   starr            3\n",
       "Revolver           Lennon           6\n",
       "                   harrison         3\n",
       "                   mccartney        4\n",
       "                   starr            1\n",
       "RubberSoul         harrison         1\n",
       "                   mccartney       10\n",
       "                   starr            3\n",
       "SgtPepper          Lennon           3\n",
       "                   mccartney        8\n",
       "                   starr            2\n",
       "WhiteAlbum         Lennon           8\n",
       "                   harrison         1\n",
       "                   mccartney       18\n",
       "                   starr            3\n",
       "WithTheBeatles     Lennon           2\n",
       "                   harrison         3\n",
       "                   mccartney        5\n",
       "                   starr            4\n",
       "YellowSubmarine    Lennon           5\n",
       "                   mccartney        6\n",
       "                   starr            2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.groupby([\"album\", \"predictions\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
